# Grady's QMD Work

## Reading in the Data

```{r}
# Loading the packages
library(tidyverse)
library(ggplot2)
library(dplyr)
library(class)
library(caret)
library(pROC)
library(glmnet)
library(GGally)
library(mgcv)
library(tidyr)

# Loading the data
df <- read.csv("~/STA-325-Final-Project/Data/data.csv")
#df <- df |>
#  select(-X)

data <- df %>% select(-X)

df <- data.frame(data)
```


## Lasso without interactions
```{r}
# 1 = malignant, 0 = benign
df$diagnosis <- ifelse(df$diagnosis == "M", 1, 0)

# Use LASSO for variable selection
df <- df[ , !names(df) %in% c("id", "X", "Unnamed..32") ] # remove id columns

X <- model.matrix( ~ ., data = df)[, -1]
y <- df$diagnosis

set.seed(123) 
n <- nrow(X)
train_idx <- sample(seq_len(n), size = 0.8 * n)

X_train1 <- X[train_idx, ]
X_train <- X_train1[, -1]
X_test1  <- X[-train_idx, ]
X_test <- X_test1[, -1]
y_train <- y[train_idx]
y_test  <- y[-train_idx]

cvfit <- cv.glmnet(
  x = X_train,
  y = y_train,
  family = "binomial",
  alpha = 1,        # LASSO
  nfolds = 5        # 5-fold CV
)

plot(cvfit) 
print(cvfit$lambda.min)

prob_test <- predict(cvfit, newx = X_test, s = "lambda.min", type = "response")

# Turn into class predictions
pred_test <- ifelse(prob_test > 0.5, 1, 0)

# evaluate diff thresholds to reduce chances of false negatives
# threshold <- 0.3
# pred_test_adj <- ifelse(prob_test > threshold, 1, 0)

# table(pred_test_adj, y_test)

# Accuracy
mean(pred_test == y_test)

# 98% accuracy on test data
```

Getting the coefficients which are in the lasso model. 
```{r}
coef_min <- coef(cvfit, s = "lambda.min")
coef_df <- as.data.frame(as.matrix(coef_min))
coef_df$feature <- rownames(coef_df)
names(coef_df)[1] <- "coefficient"

# Filtering for coefficients which aren't 0
feature_list <- coef_df |>
  filter(coefficient > 0) |>
  pull(feature)
```


```{r}
# predicted probabilities (logistic) at lambda.min
prob_test <- predict(cvfit, newx = X_test, s = "lambda.min", type = "response")
# convert to numeric vector
prob_test <- as.numeric(prob_test)

# default threshold 0.5 -> predicted class
## THIS IS WHERE WE CHANGE THRESHOLD
pred_class <- ifelse(prob_test >= 0.5, 1, 0)

```

```{r}
# AUC
roc_obj <- roc(y_test, prob_test)
auc_val <- auc(roc_obj)
print(auc_val)
plot(roc_obj, main = paste("AUC =", round(auc_val, 3)))

# confusion matrix at threshold 0.5
table(Predicted = pred_class, Actual = y_test)

# other metrics
accuracy <- mean(pred_class == y_test)
sens <- sum(pred_class == 1 & y_test == 1) / sum(y_test == 1)
spec <- sum(pred_class == 0 & y_test == 0) / sum(y_test == 0)
c(accuracy = accuracy, sensitivity = sens, specificity = spec)

```
Code for choosing an optimal threshold using the Youden index:
```{r}
coords <- coords(roc_obj, "best", ret = c("threshold","sensitivity","specificity"), best.method = "youden")
coords
```

## Building the GAM Model
```{r}
print(feature_list)
```

The first thing we want to do is to explore all of the possible interactions between these variables. 

[Oct. 25th lecture] Generalized Additive Models allow for flexble nonlinearities in several variables, but retains the additive structure of linear models. A GAM presumes that the regression model can be split into separate nonlinear functions for each predictor. This allows us to investigate and interpet nonlinear effects on each predictor separately, without any need for interactions. When using a GAM, we are less concerned with coefficients and more with the plot. You can use anova() to compare GAM models where the p-value is evidence for nonlinear effects. You can also use GAMs for classification using the logit transformation of the response. 

Advantages:
- Flexible nonlinear models for each predictor
- Generally give better predictive power than linear regression
- Additive models allow us to examine the effect of each predictor individually and is more interpetable
- Computationally quick to fit since you are just formulating the linear model

Disadvantages:
- Additive models may miss important interaction effects when they are needed

We want to use GAMs since they are composed of a sum of smooth functions of features instead of or in addition to the standard linear features. With GAMs, we deal with some additive function of inputs which won't require the y to necessarily be a linear function of x. To build a GAM, choose a bsis which is a space of functions for which f is some element of it. 
https://m-clark.github.io/generalized-additive-models/application.html.

## Building a Scatterplot Matrix in R
```{r}
cor_plot <- ggpairs(data[, feature_list])
ggsave("cor_plot.png", cor_plot, width = 12, height = 12, dpi = 300)
```

We notice that many of the variables are statistically significant according to the correlation test which is included in ggpairs().

First, I will just build a GAM model and then when I have a good idea of what models may be appropriate I'll incorporate 5-fold CV. 

```{r}
# Just getting the data for the features from the lasso model

train2 <- as.data.frame(X_train1) |>
  select(all_of(feature_list), diagnosis)
test2 <- as.data.frame(X_test1) |>
  select(all_of(feature_list), diagnosis)

```

Thin-Plate regression is the default type of spline with no need to choose know locations as they are automatically chosen. This is good for nonlinear relationships with minimal tuning and are good when unsure which spline to use. REML stands for Restricted Maximum Likelihood and is a statistical technique for fitting linear mixed models and estimating variance. REML is preferred over standard Maximum Likelihood because it provides less baised estimates for variance components. 

```{r}
m_tp  <- gam(diagnosis ~ s(smoothness_se, bs = "tp", 
                           k = 10), 
            data = train2,
            family = binomial(link = "logit"), 
            method = "REML")
```

The cubic spline regression uses a fixed set of knots but can extrapolate oddly at boundaries. 
```{r}
m_cr  <- gam(diagnosis ~ s(smoothness_se, bs = "cr", 
                           k = 10), 
            data = train2,
            family = binomial(link = "logit"), 
            method = "REML")

```

Exploring shrinkage of terms
```{r}
m_tp_sel  <- gam(diagnosis ~ s(smoothness_se, bs = "tp", 
                           k = 10), 
            data = train2,
            family = binomial(link = "logit"), 
            method = "REML",
            select = TRUE)
```

Comparing the different models

```{r}
models <- list(tp = m_tp, cr = m_cr, tp_sel = m_tp_sel)
compare_df <- tibble(
  model = names(models),
  edf = map_dbl(models, ~ sum(summary(.x)$s.table[ , "edf"], na.rm = TRUE)),
  logLik = map_dbl(models, logLik),
  AIC = map_dbl(models, AIC),
  REML = map_dbl(models, ~ .x$gcv.ubre) # optional measure stored in object
)
print(compare_df)
```
Overall, it appears as though the cubic spline performs the best. 
```{r}
# Diagnostics
gam.check(m_cr)    # look at k-index and residuals
# or
k.check(m_cr) 
```

Building a visual comparison for the model
```{r}
# prepare grid across Income
grid <- tibble(smoothness_se = seq(min(train2$smoothness_se, na.rm = TRUE),
                            max(train2$smoothness_se, na.rm = TRUE),
                            length.out = 200))

# optional: if models include other covariates, set them to typical values for prediction:
# grid <- grid %>% mutate(other_cov = median(df$other_cov, na.rm = TRUE), ...)

preds <- map_dfr(models, function(mod) {
  p_link <- predict(mod, newdata = grid, type = "link", se.fit = TRUE)
  tibble(
    smoothness_se = grid$smoothness_se,
    model = deparse(substitute(mod)),  # we'll replace model name next
    fit_link = p_link$fit,
    se_link  = p_link$se.fit,
    fit_resp = plogis(p_link$fit),                 # inverse logit -> predicted probability
    upr = plogis(p_link$fit + 2 * p_link$se.fit),
    lwr = plogis(p_link$fit - 2 * p_link$se.fit)
  )
}, .id = "model_id")

# fix model names: .id currently 1..n, replace with real names
preds$model <- rep(names(models), each = nrow(grid))

# Plot predicted probability (response scale)
ggplot(preds, aes(x = smoothness_se, y = fit_resp, color = model)) +
  geom_line(size = 1) +
  geom_ribbon(aes(ymin = lwr, ymax = upr, fill = model), alpha = 0.15, color = NA) +
  theme_minimal() +
  labs(y = "Predicted probability", title = "GAM spline basis comparison (binomial, logit link)")

# If you want to examine the logit (link) scale instead:
ggplot(preds, aes(x = smoothness_se, y = fit_link, color = model)) +
  geom_line(size = 1) +
  geom_ribbon(aes(ymin = fit_link - 2*se_link, ymax = fit_link + 2*se_link, fill = model),
              alpha = 0.12, color = NA) +
  labs(y = "Fitted logit (link)", title = "Linear predictor (logit) across Income")

```
Based on the visual above, I prefer the cubic spline since it doesn't increase it's probability as fact as the thin-plate spline which is more volatile. The problem with the thin-plate with selection is that the probabilities are very much bound between 0.25 and 0.5 which doesn't seem as realistic. The next step is to determine how I can add other splines to the GAM model. 

Chat suggested to add smoothness only when nonlinearity in the variables is suspected. Since we are predicting a binary outcome, I will use the predictions from the logistic regression above to try and visualize nonlinearity. 

Now, we need to figure out how to visualize potential nonlinearity. I was thinking we could use the predicted probabilities from the lasso logistic model as the "ground truth" although this might not be the best idea since this is in itself another model. 
Chat helped me write the below code which is calculating the average number of diagnoses for each of the bins of smoothness and then plots the line of best fit. Based on the resuls for smoothness, I'd say it's fair to assume that there is a nonlinear relationship between smoothness and the diagnosis. Below are simila rplos for the rest of the the variables.
```{r}
library(dplyr)
library(ggplot2)
library(purrr)

nbins <- 20
yvar <- "diagnosis"       # your binary outcome

# Function that bins & plots one variable
make_binned_plots <- function(df, xvar, yvar, nbins = 20) {
  
  # 1) Compute bins
  binned <- df %>%
    mutate(bin = ntile(.data[[xvar]], nbins)) %>%
    group_by(bin) %>%
    summarise(
      x_mid = mean(.data[[xvar]], na.rm = TRUE),
      n     = n(),
      prop  = mean(.data[[yvar]], na.rm = TRUE),
      .groups = "drop"
    ) %>%
    mutate(
      se    = sqrt(prop * (1 - prop) / pmax(n, 1)),
      lower = pmax(0, prop - 1.96 * se),
      upper = pmin(1, prop + 1.96 * se),
      eps   = 1e-3,
      logit = log((prop + eps) / (1 - prop + eps))
    )
  
  # 2) Proportion plot
  p_prop <- ggplot(binned, aes(x = x_mid, y = prop)) +
    geom_point(size = 2) +
    geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.01) +
    labs(
      title = paste("Binned proportion for", xvar),
      x = xvar,
      y = "Observed proportion"
    ) +
    theme_minimal()
  
  # 3) Logit plot
  p_logit <- ggplot(binned, aes(x = x_mid, y = logit)) +
    geom_point(size = 2) +
    geom_smooth(method = "loess", se = TRUE) +
    labs(
      title = paste("Binned log-odds for", xvar),
      x = xvar,
      y = "Estimated log-odds"
    ) +
    theme_minimal()
  
  return(list(binned = binned, prop_plot = p_prop, logit_plot = p_logit))
}

# ---- Loop over all predictors ----
results <- map(feature_list, ~ make_binned_plots(df, .x, yvar))
names(results) <- feature_list

## Showing all of the plots
results[["smoothness_se"]]$logit_plot
results[["concave.points_mean"]]$logit_plot
results[["radius_se"]]$logit_plot
results[["radius_worst"]]$logit_plot
results[["texture_worst"]]$logit_plot
results[["smoothness_worst"]]$logit_plot
results[["concavity_worst"]]$logit_plot
results[["concave.points_worst"]]$logit_plot
results[["symmetry_worst"]]$logit_plot






```

After looking at the results above, it appears as thought the worst offenders of nonlinearity are:
- smoothness_se
- radius_worst
- concavity_worst
- texture_worst

Now, we can easily compare a GLM vs GAM fit.
```{r}

results <- map_dfr(feature_list, function(var) {
  
  # build formulas
  form_glm <- as.formula(paste("diagnosis ~", var))
  form_gam <- as.formula(paste("diagnosis ~ s(", var, ", k=10)", sep = ""))
  
  # fit models
  mod_glm <- glm(form_glm, data=df, family = binomial("logit"))
  mod_gam <- gam(form_gam, data=df, bs="cr",
                 family = binomial("logit"), method="REML")
  
  # AIC comparison
  aic_vals <- AIC(mod_glm, mod_gam)
  
  # Likelihood ratio test (nested model test)
  an <- anova(mod_glm, mod_gam, test="Chisq")
  pval <- an$`Pr(>Chi)`[2]   # GAM vs GLM

  
  tibble(
    variable = var,
    glm_AIC  = aic_vals$AIC[1],
    gam_AIC  = aic_vals$AIC[2],
    delta_AIC = aic_vals$AIC[1] - aic_vals$AIC[2],
    LRT_pvalue = an$`Pr(>Chi)`[2],  # the p-value comparing GLM vs GAM
    significant_0.01 = ifelse(!is.na(pval) & pval < 0.01, "YES", "NO")

  )
})
```



If GAM AIC is much, lower, there is strong evidence of nonlinearity. Additionally, a significant p-value indicates that the spline improves the model fit and nonlinearity exists. 

From the results above, we have decided to include splines for based on the drop in AIC when using the GAM model:
- smoothness_se
- texture_worst
- concavity_worst






```{r}
### LATER 
# 5-fold CV
cv_5 <- trainControl(method = "cv", number = 5)

model <- train(
  y ~ s(Income, bs = "tp", k = 10) + . - Income,
  data = train2,
  method = "gam",
  family = binomial(link = "logit"),
  trControl = cv_5
)

model
```



## Lasso Logistic with Interaction Terms
Now, the interaction terms using just the significant terms from above will be added.
```{r}
# Extracing the relevant features to use as interactions
selected_features <- coef_df |>
  filter(coefficient > 0) |>
  pull(feature)

selected_features

```

```{r}

# Use LASSO for variable selection
df2 <- df[ , !names(df) %in% c("id", "X", "Unnamed..32") ] # remove id columns
df2 <- df2[ , names(df2) %in% c(selected_features, "diagnosis")]

X <- model.matrix(diagnosis ~ (.)^2, data = df2)[, -1] # adding interactions
y <- df$diagnosis

set.seed(123) 
n <- nrow(X)
train_idx <- sample(seq_len(n), size = 0.8 * n)

X_train <- X[train_idx, ]
X_test  <- X[-train_idx, ]
y_train <- y[train_idx]
y_test  <- y[-train_idx]

cvfit2 <- cv.glmnet(
  x = X_train,
  y = y_train,
  family = "binomial",
  alpha = 1,        # LASSO
  nfolds = 5        # 5-fold CV
)

plot(cvfit2) 
print(cvfit2$lambda.min)

prob_test <- predict(cvfit2, newx = X_test, s = "lambda.min", type = "response")

# Turn into class predictions
pred_test <- ifelse(prob_test > 0.5, 1, 0)

# evaluate diff thresholds to reduce chances of false negatives
# threshold <- 0.3
# pred_test_adj <- ifelse(prob_test > threshold, 1, 0)

# table(pred_test_adj, y_test)

# Accuracy
mean(pred_test == y_test)

# 98% accuracy on test data
```
```{r}
# Extracting the coefficients in the lasso model
coef_min2 <- coef(cvfit2, s = "lambda.min")
coef_df2 <- as.data.frame(as.matrix(coef_min2))
coef_df2$feature <- rownames(coef_df2)
names(coef_df2)[1] <- "coefficient"

# Filtering for coefficients which aren't 0
coef_df2 |>
  filter(coefficient > 0) 
```
## Hierarchical Logistic Lasso Model
```{r}
# install.packages("glinternet")
library(glinternet)

# X must be a numeric matrix; categorical variables require specifying numLevels
X <- model.matrix(diagnosis ~ (.)^2, data = df2)[, -1] # adding interactions
y <- df$diagnosis

numLevels <- rep(1, ncol(X))  # 1 = numeric, >1 = categorical levels

fit <- glinternet(X, y, numLevels = numLevels, family = "binomial")

summary(fit)
coef(fit, s = "lambda.min")


```



## Interaction Terms
From Laura's code to get the interactions
```{r}
corr_matrix <- df |> 
  select(ends_with("_mean")) |> 
  cor()

corrplot::corrplot(corr_matrix, method = "color", type = "upper", tl.cex = 0.7)
```

```{r}
corr_matrix




```


Interactions:
- Worst: all involved fractal dimension which isn't considered significant in our model
- 

## EDA for Worst

Worst: mean of the three largest values (mean of the "outliers")
- Will give an idea of how far the mean of the largest values are from the true mean

## Building the KNN Model


```{r}
# Building the basic KNN Model
set.seed(325)

# Train/test split
train_idx <- createDataPartition(df$diagnosis, p = 0.7, list = FALSE)
train <- df[train_idx, ]
test <- df[-train_idx, ]

# trainControl: repeated CV, keep class probs for ROC
ctrl <- trainControl(
  method = "repeatedcv",
  number = 10,
  repeats = 3,
  classProbs = TRUE,
  summaryFunction = twoClassSummary,
  savePredictions = "final"
)

# Grid of odd k values to try
kgrid <- expand.grid(k = seq(1, 25, by = 2))

# Fitting the model
knn_fit <- train(
  diagnosis ~ .,
  data = train,
  method = "knn",
  tuneGrid = kgrid,
  preProcess = c("center", "scale"),
  trControl = ctrl,
  metric = "ROC"
)

print(knn_fit)
plot(knn_fit)

```

```{r}
# Building the best model
best_k <- knn_fit$bestTune$k
cat("Best k:", best_k, "\n")
```
```{r}
# Predict on test set (class + prob)
pred_class <- predict(knn_fit, newdata = test)
pred_prob  <- predict(knn_fit, newdata = test, type = "prob")[, "M"]

# Refactoring the actual data
test_actual <- factor(test$diagnosis, levels = c("B","M"))

# Confusion matrix (use "yes" as positive)
conf <- confusionMatrix(pred_class, test_actual, positive = "M")
print(conf)


```

```{r}
# ROC / AUC
roc_obj <- roc(response = test$diagnosis, predictor = pred_prob, levels = c("B", "M"))
auc_val <- auc(roc_obj)
cat("Test AUC:", round(auc_val, 4), "\n")

# Optional: plot ROC
plot(roc_obj, main = paste("ROC curve (AUC =", round(auc_val,3), ")"))
```

I'm a little skeptical that this is too good of a model for the problem especially since the confusion matrix shows 100% accuracy with its predictions. 

## Getting a PCA Visual for the predictors
```{r}
# Getting the numeric columns
numeric_columns <- names(df)[sapply(df, is.numeric)]
numeric_columns <- setdiff(numeric_columns, c("diagnosis", "id"))

# PCA on training data
pca_model <- prcomp(train[, numeric_columns], scale. = TRUE)

train_pca <- data.frame(
  PC1 = pca_model$x[,1],
  PC2 = pca_model$x[,2],
  diagnosis = train$diagnosis
)
```

Note: this is fitting a different KNN model than the one that was tested above
```{r}
# Fit KNN in PCA space
train_x <- train_pca[, 1:2]

# Grid for visualization
x_range <- seq(min(train_x$PC1)-1, max(train_x$PC1)+1, length.out=200)
y_range <- seq(min(train_x$PC2)-1, max(train_x$PC2)+1, length.out=200)
grid <- expand.grid(PC1=x_range, PC2=y_range)

grid_pred <- knn(train = train_x, test = grid, cl = train_pca$diagnosis, k = 5)

grid$pred <- grid_pred

# Plot
ggplot() +
  geom_tile(data = grid, 
            aes(PC1, PC2, fill = pred),
            alpha=0.35) +
  geom_point(data = train_pca, aes(PC1, PC2, color = diagnosis), size=2) +
  theme_minimal() +
  ggtitle("KNN Decision Boundary in PCA Space")
```


### Table Comparing Benign vs Malignant
```{r}
# Creating a new dataframe
stats_worst <- df |>
  group_by(diagnosis) |>
  summarise(
    count = n(),
    mean_radius = mean(radius_worst),
    median_radius = median(radius_worst),
    se_radius = sd(radius_worst),
    mean_texture = mean(texture_worst),
    median_texture = median(texture_worst),
    se_texture = sd(texture_worst),
    mean_perimeter = mean(perimeter_worst),
    median_perimeter = median(perimeter_worst),
    se_perimeter = sd(perimeter_worst),
    mean_area = mean(area_worst),
    median_area = median(area_worst),
    se_area = sd(area_worst),
    mean_smoothness = mean(smoothness_worst),
    median_smoothness = median(smoothness_worst),
    se_smoothness = sd(smoothness_worst),
    mean_compactness = mean(compactness_worst),
    median_compactness = median(compactness_worst),
    se_compactness = sd(compactness_worst),
    mean_concavity = mean(concavity_worst),
    median_concavity = median(concavity_worst),
    se_concavity = sd(concavity_worst),
    mean_concave.points = mean(concave.points_worst),
    median_concave.points = median(concave.points_worst),
    se_concave.points = sd(concave.points_worst),
    mean_symmetry = mean(symmetry_worst),
    median_symmetry = median(symmetry_worst),
    se_symmetry = sd(symmetry_worst),
    mean_fractal_dimension = mean(fractal_dimension_worst),
    median_fractal_dimension = median(fractal_dimension_worst),
    se_fractal_dimension_worst = sd(fractal_dimension_worst),
  )

# Transposing the dataframe
stats_worst_t <- t(stats_worst)

# Making the diagnosis the column
colnames(stats_worst_t) <- as.character(unlist(stats_worst_t[1, ])) 
stats_worst_t <- stats_worst_t[-1, ]  # remove the first row

```

Observations:
**Note: These worst values are only being calculated from 3 observations in each mass which are determined to be the "worst" so it's important to keep in mind the ow sample size when comparing an calculations for benign and malignant
- Malignant tissue has a higher mean worst radius which is 1.5 times that of benign tissue
- The mean texture and mean perimeter are also higher for malignant 
- Mean area is nearly triple for malignant than benign while the standard error is nearly quadruple
- Mean compactness is also nearly double for malignant
- Mean concavity is nearly triple as well as mean concave.points (the standard error is also much higher for the mean concave.points)
- Mean symmetry is fairly similar across both types of tissue althogh malignant has a higher standard error
- Fractical dimension is slightly higher for malignant than benign tissue
- Most of the standard errors are fairly similar which is interesting because it gives stronger evidence that the features with higher means for malignant will likely have higher means and could be used as an indicator of whether the tissue is benign or malignant based on the average of the three most extreme points

### Basic Distributions Separated by Tissue Type

```{r}
# create ordered levels and a reversed palette
levels_diag <- levels(factor(df$diagnosis))         # preserve factor ordering
pal <- rev(scales::hue_pal()(length(levels_diag)))  # reversed palette
names(pal) <- levels_diag    
```

#### Radius

```{r}
# Basic distributions of these variables
ggplot(df) + 
  geom_histogram(aes(x = radius_worst, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  geom_vline(data= stats_worst, aes(xintercept = mean_radius, color = diagnosis), 
             linetype = "dashed") + 
  geom_vline(data= stats_worst, aes(xintercept = median_radius, color = diagnosis), 
             linetype = "solid") + 
  labs(x = "Radius (worst)", y = "Count",
       title = "Distribution of the Worst Radius by Diagnosis")

```
The above graph shows the worst radius based on whether the tissue is benign or malignant. The mean values are in the dashed lines and the median values are the solid lines.

We also see that the benign distribution has a mean very close to the median, whereas the malignant distribution has a mean which is greater than the median due to outliers.

Both look fairly normally distributed, but we may want to address the outliers in the malignant distribution.

#### Texture
```{r}
# Basic distributions of these variables
ggplot(df) + 
  geom_histogram(aes(x = texture_worst, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  geom_vline(data= stats_worst, aes(xintercept = mean_texture, color = diagnosis), 
             linetype = "dashed") + 
  geom_vline(data= stats_worst, aes(xintercept = median_texture, color = diagnosis), 
             linetype = "solid") + 
  labs(x = "Texture (worst)", y = "Count",
       title = "Distribution of the Worst Texture by Diagnosis")
```

These distributins have a fairly similar shape and both look roughly normal although there are some potential outliers for the malignant tissue. Transformation is likely not needed for this distribution unless we want to correct for outliers.

#### Perimeter
```{r}
# Basic distributions of these variables
ggplot(df) + 
  geom_histogram(aes(x = perimeter_worst, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  geom_vline(data= stats_worst, aes(xintercept = mean_perimeter, color = diagnosis), 
             linetype = "dashed") + 
  geom_vline(data= stats_worst, aes(xintercept = median_perimeter, color = diagnosis), 
             linetype = "solid") + 
  labs(x = "Perimeter (worst)", y = "Count",
       title = "Distribution of the Worst Perimeter by Diagnosis")

```

For Perimeter we notice that malignant tissue is more right-skewed based on the fact that the mean is a bit higher than the median. Although a transformation could be useful to correct for this asymmetry, we might not want to transform the distributions since the malignant distribution is fairly normal.

#### Area
```{r}
# Basic distributions of these variables
ggplot(df) + 
  geom_histogram(aes(x = area_worst, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  geom_vline(data= stats_worst, aes(xintercept = mean_area, color = diagnosis), 
             linetype = "dashed") + 
  geom_vline(data= stats_worst, aes(xintercept = median_area, color = diagnosis), 
             linetype = "solid") + 
  labs(x = "Area (worst)", y = "Count",
       title = "Distribution of the Worst Area by Diagnosis")
```
This is one of the first variables where area is very differently distributed between malignant and benign tissue. It might be worth further exploring area for this reason, especially given how strong of a right skew the malignant tissue has.

#### Smoothness
```{r}
# Basic distributions of these variables
ggplot(df) + 
  geom_histogram(aes(x = smoothness_worst, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  geom_vline(data= stats_worst, aes(xintercept = mean_smoothness, color = diagnosis), 
             linetype = "dashed") + 
  geom_vline(data= stats_worst, aes(xintercept = median_smoothness, color = diagnosis), 
             linetype = "solid") + 
  labs(x = "Smoothness (worst)", y = "Count",
       title = "Distribution of the Worst Smoothness by Diagnosis")
```

This distribution is fairly similar across both tissues although malignant does tend to have a higher mean and medina value of smoothness.

#### Compactness
```{r}
# Basic distributions of these variables
ggplot(df) + 
  geom_histogram(aes(x = compactness_worst, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  geom_vline(data= stats_worst, aes(xintercept = mean_compactness, color = diagnosis), 
             linetype = "dashed") + 
  geom_vline(data= stats_worst, aes(xintercept = median_compactness, color = diagnosis), 
             linetype = "solid") + 
  labs(x = "Compactness (worst)", y = "Count",
       title = "Distribution of the Worst Compactness by Diagnosis")
```

Similarly to area, the compactness is much more spread out for malignant tissue and has a stronger presence of outliers. However, the benign tissue is also right skewed a bit. Applying a transformation to both of these distributions might help to address the normality assumptions. 

#### Concavity
```{r}
# Basic distributions of these variables
ggplot(df) + 
  geom_histogram(aes(x = concavity_worst, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  geom_vline(data= stats_worst, aes(xintercept = mean_concavity, color = diagnosis), 
             linetype = "dashed") + 
  geom_vline(data= stats_worst, aes(xintercept = median_concavity, color = diagnosis), 
             linetype = "solid") + 
  labs(x = "Concavity (worst)", y = "Count",
       title = "Distribution of the Worst Concavity by Diagnosis")
```

Again, both malignant and benign are right skewed but benign has a stronger right skew in this distribution. Applying a transformation will be usefult o address the violation of normality assumptions.

#### Texture
```{r}
# Basic distributions of these variables
ggplot(df) + 
  geom_histogram(aes(x = concave.points_worst, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  geom_vline(data= stats_worst, aes(xintercept = mean_concave.points, color = diagnosis), 
             linetype = "dashed") + 
  geom_vline(data= stats_worst, aes(xintercept = median_concave.points, color = diagnosis), 
             linetype = "solid") + 
  labs(x = "Concave Points (worst)", y = "Count",
       title = "Distribution of the Worst Concave Points by Diagnosis")

```

The mean concave points are both fairly normally distributed with the malignant tissue having a much higher mean an median when comparing the types of tissue which could be something to explore further.

#### Symmetry
```{r}
# Basic distributions of these variables
ggplot(df) + 
  geom_histogram(aes(x = symmetry_worst, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  geom_vline(data= stats_worst, aes(xintercept = mean_symmetry, color = diagnosis), 
             linetype = "dashed") + 
  geom_vline(data= stats_worst, aes(xintercept = median_symmetry, color = diagnosis), 
             linetype = "solid") + 
  labs(x = "Symmetry (worst)", y = "Count",
       title = "Distribution of the Worst Symmetry by Diagnosis")

```
Symmetry has closer median values but malignant tissue has several outliers leading to a right skew in the distribution.

#### Fractal Dimension
```{r}
# Basic distributions of these variables
ggplot(df) + 
  geom_histogram(aes(x = fractal_dimension_worst, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  geom_vline(data= stats_worst, aes(xintercept = mean_fractal_dimension, 
                                    color = diagnosis), 
             linetype = "dashed") + 
  geom_vline(data= stats_worst, aes(xintercept = median_fractal_dimension, 
                                    color = diagnosis), 
             linetype = "solid") + 
  labs(x = "Fractal Dimension (worst)", y = "Count",
       title = "Distribution of the Worst Fractal Dimension by Diagnosis")
```
Both of these distributions are right skewed, but they are fairly close in terms of how they overal over each other. Transforming this feature might be a good idea to address the normality assumptions.

### Quantifying the distance of the worst from the mean

```{r}
# Building a dataframe to quantify the distance between the worst and the mean
df <- df |>
  mutate(
    radius_worst_dist = radius_worst - radius_mean,
    radius_worst_stand = radius_worst_dist / radius_se,
    texture_worst_dist = texture_worst - texture_mean,
    texture_worst_stand = texture_worst_dist / texture_se, 
    perimeter_worst_dist = perimeter_worst - perimeter_mean,
    perimeter_worst_stand = 
      perimeter_worst_dist / perimeter_se,
    area_worst_dist = area_worst - area_mean,
    area_worst_stand = area_worst_dist / area_se, 
    smoothness_worst_dist = 
      smoothness_worst - smoothness_mean,
    smoothness_worst_stand = 
      smoothness_worst_dist / smoothness_se,
    compactness_worst_dist = 
      compactness_worst - compactness_mean,
    compactness_worst_stand = 
      compactness_worst_dist / compactness_se, 
    concavity_worst_dist = 
      concavity_worst - concavity_mean,
    concavity_worst_stand = 
     concavity_worst_dist / concavity_se,
    concave.points_worst_dist = 
      concave.points_worst - concave.points_mean,
    concave.points_worst_stand = 
      concave.points_worst_dist / concave.points_se, 
    symmetry_worst_dist = 
      symmetry_worst - symmetry_mean,
    symmetry_worst_stand = 
      symmetry_worst_dist / symmetry_se, 
    fractal_dimension_worst_dist = 
       fractal_dimension_worst -  fractal_dimension_mean,
    fractal_dimension_worst_stand = 
       fractal_dimension_worst_dist /  fractal_dimension_se, 
  )

```

# Visualizing Standard Error Boxplots

#### Radius
```{r}
# Visualizing the distances
ggplot(df) + 
  geom_boxplot(aes(x = radius_worst_dist, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  labs(x = "Radius Distance (worst)", y = "Count",
       title = "Distribution of the Radius Distance by Diagnosis")

# Visualizing the standard errors
ggplot(df) + 
  geom_boxplot(aes(x = radius_worst_stand, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  labs(x = "Radius Standard Errors (worst)", y = "Count",
       title = "Distribution of the Radius Standard Errors by Diagnosis")
```
#### Texture
```{r}
# Visualizing the distances
ggplot(df) + 
  geom_boxplot(aes(x = texture_worst_dist, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  labs(x = "Texture Distance (worst)", y = "Count",
       title = "Distribution of the Texture Distance by Diagnosis")

# Visualizing the standard errors
ggplot(df) + 
  geom_boxplot(aes(x = texture_worst_stand, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  labs(x = "Texture Standard Errors (worst)", y = "Count",
       title = "Distribution of the Texture Standard Errors by Diagnosis")
```

#### Perimeter
```{r}
# Visualizing the distances
ggplot(df) + 
  geom_boxplot(aes(x = perimeter_worst_dist, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  labs(x = "Perimeter Distance (worst)", y = "Count",
       title = "Distribution of the Perimeter Distance by Diagnosis")

# Visualizing the standard errors
ggplot(df) + 
  geom_boxplot(aes(x = perimeter_worst_stand, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  labs(x = "Perimeter Standard Errors (worst)", y = "Count",
       title = "Distribution of the Perimeter Standard Errors by Diagnosis")
```

#### Area
```{r}
# Visualizing the distances
ggplot(df) + 
  geom_boxplot(aes(x = area_worst_dist, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  labs(x = "Area Distance (worst)", y = "Count",
       title = "Distribution of the Area Distance by Diagnosis")

# Visualizing the standard errors
ggplot(df) + 
  geom_boxplot(aes(x = area_worst_stand, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  labs(x = "Area Standard Errors (worst)", y = "Count",
       title = "Distribution of the Area Standard Errors by Diagnosis")
```

#### Smoothness
```{r}
# Visualizing the distances
ggplot(df) + 
  geom_boxplot(aes(x = smoothness_worst_dist, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  labs(x = "Smoothness Distance (worst)", y = "Count",
       title = "Distribution of the Smoothness Distance by Diagnosis")

# Visualizing the standard errors
ggplot(df) + 
  geom_boxplot(aes(x = smoothness_worst_stand, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  labs(x = "Smoothness Standard Errors (worst)", y = "Count",
       title = "Distribution of the Smoothness Standard Errors by Diagnosis")
```

#### Compactness
```{r}
# Visualizing the distances
ggplot(df) + 
  geom_boxplot(aes(x = compactness_worst_dist, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  labs(x = "Compactness Distance (worst)", y = "Count",
       title = "Distribution of the Compactness Distance by Diagnosis")

# Visualizing the standard errors
ggplot(df) + 
  geom_boxplot(aes(x = compactness_worst_stand, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  labs(x = "Compactness Standard Errors (worst)", y = "Count",
       title = "Distribution of the Compactness Standard Errors by Diagnosis")
```

#### Concavity
```{r}
# Visualizing the distances
ggplot(df) + 
  geom_boxplot(aes(x = concavity_worst_dist, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  labs(x = "Concavity Distance (worst)", y = "Count",
       title = "Distribution of the Concavity Distance by Diagnosis")

# Visualizing the standard errors
ggplot(df) + 
  geom_boxplot(aes(x = concavity_worst_stand, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  labs(x = "Concavity Standard Errors (worst)", y = "Count",
       title = "Distribution of the Concavity Standard Errors by Diagnosis")
```


#### Concave Points
```{r}
# Visualizing the distances
ggplot(df) + 
  geom_boxplot(aes(x = concave.points_worst_dist, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  labs(x = "Concave Points Distance (worst)", y = "Count",
       title = "Distribution of the Concave Points Distance by Diagnosis")

# Visualizing the standard errors
ggplot(df) + 
  geom_boxplot(aes(x = concave.points_worst_stand, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  labs(x = "Concave Points Standard Errors (worst)", y = "Count",
       title = "Distribution of the Concave Points Standard Errors by Diagnosis")
```

#### Symmetry
```{r}
# Visualizing the distances
ggplot(df) + 
  geom_boxplot(aes(x = symmetry_worst_dist, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  labs(x = "Symmetry Distance (worst)", y = "Count",
       title = "Distribution of the Symmetry Distance by Diagnosis")

# Visualizing the standard errors
ggplot(df) + 
  geom_boxplot(aes(x = symmetry_worst_stand, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  labs(x = "Symmetry Standard Errors (worst)", y = "Count",
       title = "Distribution of the Symmetry Standard Errors by Diagnosis")
```

#### Fractal Dimension
```{r}
# Visualizing the distances
ggplot(df) + 
  geom_boxplot(aes(x = fractal_dimension_worst_dist, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  labs(x = "Fractal Dimension Distance (worst)", y = "Count",
       title = "Distribution of the Fractal Dimension Distance by Diagnosis")

# Visualizing the standard errors
ggplot(df) + 
  geom_boxplot(aes(x = fractal_dimension_worst_stand, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  labs(x = "Fractal Dimension Standard Errors (worst)", y = "Count",
       title = "Distribution of the Fractal Dimension Standard Errors by Diagnosis")
```

