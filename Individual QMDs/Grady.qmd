# Grady's QMD Work

## Reading in the Data

```{r}
# Loading the packages
library(tidyverse)
library(ggplot2)
library(dplyr)
library(class)
library(caret)
library(pROC)
library(glmnet)



# Loading the data
df <- read.csv("~/STA-325-Final-Project/Data/data.csv")
#df <- df |>
#  select(-X)

data <- df %>% select(-X)

df <- data.frame(data)
```

## Interaction Terms
From Laura's code to get the interactions
```{r}
corr_matrix <- df |> 
  select(ends_with("_mean")) |> 
  cor()

corrplot::corrplot(corr_matrix, method = "color", type = "upper", tl.cex = 0.7)
```

```{r}
corr_matrix

```

## Lasso without interactions
```{r}

# Loading the data
df <- read.csv("~/STA-325-Final-Project/Data/data.csv")
#df <- df |>
#  select(-X)

data <- df %>% select(-X)

df <- data.frame(data)
# 1 = malignant, 0 = benign
df$diagnosis <- ifelse(df$diagnosis == "M", 1, 0)

# Use LASSO for variable selection
df <- df[ , !names(df) %in% c("id", "X", "Unnamed..32") ] # remove id columns

X <- model.matrix(diagnosis ~ ., data = df)[, -1]
y <- df$diagnosis

set.seed(123) 
n <- nrow(X)
train_idx <- sample(seq_len(n), size = 0.8 * n)

X_train <- X[train_idx, ]
X_test  <- X[-train_idx, ]
y_train <- y[train_idx]
y_test  <- y[-train_idx]

cvfit <- cv.glmnet(
  x = X_train,
  y = y_train,
  family = "binomial",
  alpha = 1,        # LASSO
  nfolds = 5        # 5-fold CV
)

plot(cvfit) 
print(cvfit$lambda.min)

prob_test <- predict(cvfit, newx = X_test, s = "lambda.min", type = "response")

# Turn into class predictions
pred_test <- ifelse(prob_test > 0.5, 1, 0)

# evaluate diff thresholds to reduce chances of false negatives
# threshold <- 0.3
# pred_test_adj <- ifelse(prob_test > threshold, 1, 0)

# table(pred_test_adj, y_test)

# Accuracy
mean(pred_test == y_test)

# 98% accuracy on test data
```

Getting the coefficients which are in the lasso model. 
```{r}
coef_min <- coef(cvfit, s = "lambda.min")
coef_df <- as.data.frame(as.matrix(coef_min))
coef_df$feature <- rownames(coef_df)
names(coef_df)[1] <- "coefficient"

# Filtering for coefficients which aren't 0
coef_df |>
  filter(coefficient > 0) 
```


```{r}
# predicted probabilities (logistic) at lambda.min
prob_test <- predict(cvfit, newx = X_test, s = "lambda.min", type = "response")
# convert to numeric vector
prob_test <- as.numeric(prob_test)

# default threshold 0.5 -> predicted class
## THIS IS WHERE WE CHANGE THRESHOLD
pred_class <- ifelse(prob_test >= 0.5, 1, 0)

```

```{r}
# AUC
roc_obj <- roc(y_test, prob_test)
auc_val <- auc(roc_obj)
print(auc_val)
plot(roc_obj, main = paste("AUC =", round(auc_val, 3)))

# confusion matrix at threshold 0.5
table(Predicted = pred_class, Actual = y_test)

# other metrics
accuracy <- mean(pred_class == y_test)
sens <- sum(pred_class == 1 & y_test == 1) / sum(y_test == 1)
spec <- sum(pred_class == 0 & y_test == 0) / sum(y_test == 0)
c(accuracy = accuracy, sensitivity = sens, specificity = spec)

```
Code for choosing an optimal threshold using the Youden index:
```{r}
coords <- coords(roc_obj, "best", ret = c("threshold","sensitivity","specificity"), best.method = "youden")
coords
```
## Lasso Logistic with Interaction Terms
Now, the interaction terms using just the significant terms from above will be added.
```{r}
# Extracing the relevant features to use as interactions
selected_features <- coef_df |>
  filter(coefficient > 0) |>
  pull(feature)

selected_features

```

```{r}

# Use LASSO for variable selection
df2 <- df[ , !names(df) %in% c("id", "X", "Unnamed..32") ] # remove id columns
df2 <- df2[ , names(df2) %in% c(selected_features, "diagnosis")]

X <- model.matrix(diagnosis ~ (.)^2, data = df2)[, -1] # adding interactions
y <- df$diagnosis

set.seed(123) 
n <- nrow(X)
train_idx <- sample(seq_len(n), size = 0.8 * n)

X_train <- X[train_idx, ]
X_test  <- X[-train_idx, ]
y_train <- y[train_idx]
y_test  <- y[-train_idx]

cvfit2 <- cv.glmnet(
  x = X_train,
  y = y_train,
  family = "binomial",
  alpha = 1,        # LASSO
  nfolds = 5        # 5-fold CV
)

plot(cvfit2) 
print(cvfit2$lambda.min)

prob_test <- predict(cvfit2, newx = X_test, s = "lambda.min", type = "response")

# Turn into class predictions
pred_test <- ifelse(prob_test > 0.5, 1, 0)

# evaluate diff thresholds to reduce chances of false negatives
# threshold <- 0.3
# pred_test_adj <- ifelse(prob_test > threshold, 1, 0)

# table(pred_test_adj, y_test)

# Accuracy
mean(pred_test == y_test)

# 98% accuracy on test data
```
```{r}
# Extracting the coefficients in the lasso model
coef_min2 <- coef(cvfit2, s = "lambda.min")
coef_df2 <- as.data.frame(as.matrix(coef_min2))
coef_df2$feature <- rownames(coef_df2)
names(coef_df2)[1] <- "coefficient"

# Filtering for coefficients which aren't 0
coef_df2 |>
  filter(coefficient > 0) 
```
## Hierarchical Logistic Lasso Model
```{r}
# install.packages("glinternet")
library(glinternet)

# X must be a numeric matrix; categorical variables require specifying numLevels
X <- model.matrix(diagnosis ~ (.)^2, data = df2)[, -1] # adding interactions
y <- df$diagnosis

numLevels <- rep(1, ncol(X))  # 1 = numeric, >1 = categorical levels

fit <- glinternet(X, y, numLevels = numLevels, family = "binomial")

summary(fit)
coef(fit, s = "lambda.min")


```



## Decision Tree
```{r}


```


Interactions:
- Worst: all involved fractal dimension which isn't considered significant in our model
- 

## EDA for Worst

Worst: mean of the three largest values (mean of the "outliers")
- Will give an idea of how far the mean of the largest values are from the true mean

## Building the KNN Model


```{r}
# Building the basic KNN Model
set.seed(325)

# Train/test split
train_idx <- createDataPartition(df$diagnosis, p = 0.7, list = FALSE)
train <- df[train_idx, ]
test <- df[-train_idx, ]

# trainControl: repeated CV, keep class probs for ROC
ctrl <- trainControl(
  method = "repeatedcv",
  number = 10,
  repeats = 3,
  classProbs = TRUE,
  summaryFunction = twoClassSummary,
  savePredictions = "final"
)

# Grid of odd k values to try
kgrid <- expand.grid(k = seq(1, 25, by = 2))

# Fitting the model
knn_fit <- train(
  diagnosis ~ .,
  data = train,
  method = "knn",
  tuneGrid = kgrid,
  preProcess = c("center", "scale"),
  trControl = ctrl,
  metric = "ROC"
)

print(knn_fit)
plot(knn_fit)

```

```{r}
# Building the best model
best_k <- knn_fit$bestTune$k
cat("Best k:", best_k, "\n")
```
```{r}
# Predict on test set (class + prob)
pred_class <- predict(knn_fit, newdata = test)
pred_prob  <- predict(knn_fit, newdata = test, type = "prob")[, "M"]

# Refactoring the actual data
test_actual <- factor(test$diagnosis, levels = c("B","M"))

# Confusion matrix (use "yes" as positive)
conf <- confusionMatrix(pred_class, test_actual, positive = "M")
print(conf)


```

```{r}
# ROC / AUC
roc_obj <- roc(response = test$diagnosis, predictor = pred_prob, levels = c("B", "M"))
auc_val <- auc(roc_obj)
cat("Test AUC:", round(auc_val, 4), "\n")

# Optional: plot ROC
plot(roc_obj, main = paste("ROC curve (AUC =", round(auc_val,3), ")"))
```

I'm a little skeptical that this is too good of a model for the problem especially since the confusion matrix shows 100% accuracy with its predictions. 

## Getting a PCA Visual for the predictors
```{r}
# Getting the numeric columns
numeric_columns <- names(df)[sapply(df, is.numeric)]
numeric_columns <- setdiff(numeric_columns, c("diagnosis", "id"))

# PCA on training data
pca_model <- prcomp(train[, numeric_columns], scale. = TRUE)

train_pca <- data.frame(
  PC1 = pca_model$x[,1],
  PC2 = pca_model$x[,2],
  diagnosis = train$diagnosis
)
```

Note: this is fitting a different KNN model than the one that was tested above
```{r}
# Fit KNN in PCA space
train_x <- train_pca[, 1:2]

# Grid for visualization
x_range <- seq(min(train_x$PC1)-1, max(train_x$PC1)+1, length.out=200)
y_range <- seq(min(train_x$PC2)-1, max(train_x$PC2)+1, length.out=200)
grid <- expand.grid(PC1=x_range, PC2=y_range)

grid_pred <- knn(train = train_x, test = grid, cl = train_pca$diagnosis, k = 5)

grid$pred <- grid_pred

# Plot
ggplot() +
  geom_tile(data = grid, 
            aes(PC1, PC2, fill = pred),
            alpha=0.35) +
  geom_point(data = train_pca, aes(PC1, PC2, color = diagnosis), size=2) +
  theme_minimal() +
  ggtitle("KNN Decision Boundary in PCA Space")
```


### Table Comparing Benign vs Malignant
```{r}
# Creating a new dataframe
stats_worst <- df |>
  group_by(diagnosis) |>
  summarise(
    count = n(),
    mean_radius = mean(radius_worst),
    median_radius = median(radius_worst),
    se_radius = sd(radius_worst),
    mean_texture = mean(texture_worst),
    median_texture = median(texture_worst),
    se_texture = sd(texture_worst),
    mean_perimeter = mean(perimeter_worst),
    median_perimeter = median(perimeter_worst),
    se_perimeter = sd(perimeter_worst),
    mean_area = mean(area_worst),
    median_area = median(area_worst),
    se_area = sd(area_worst),
    mean_smoothness = mean(smoothness_worst),
    median_smoothness = median(smoothness_worst),
    se_smoothness = sd(smoothness_worst),
    mean_compactness = mean(compactness_worst),
    median_compactness = median(compactness_worst),
    se_compactness = sd(compactness_worst),
    mean_concavity = mean(concavity_worst),
    median_concavity = median(concavity_worst),
    se_concavity = sd(concavity_worst),
    mean_concave.points = mean(concave.points_worst),
    median_concave.points = median(concave.points_worst),
    se_concave.points = sd(concave.points_worst),
    mean_symmetry = mean(symmetry_worst),
    median_symmetry = median(symmetry_worst),
    se_symmetry = sd(symmetry_worst),
    mean_fractal_dimension = mean(fractal_dimension_worst),
    median_fractal_dimension = median(fractal_dimension_worst),
    se_fractal_dimension_worst = sd(fractal_dimension_worst),
  )

# Transposing the dataframe
stats_worst_t <- t(stats_worst)

# Making the diagnosis the column
colnames(stats_worst_t) <- as.character(unlist(stats_worst_t[1, ])) 
stats_worst_t <- stats_worst_t[-1, ]  # remove the first row

```

Observations:
**Note: These worst values are only being calculated from 3 observations in each mass which are determined to be the "worst" so it's important to keep in mind the ow sample size when comparing an calculations for benign and malignant
- Malignant tissue has a higher mean worst radius which is 1.5 times that of benign tissue
- The mean texture and mean perimeter are also higher for malignant 
- Mean area is nearly triple for malignant than benign while the standard error is nearly quadruple
- Mean compactness is also nearly double for malignant
- Mean concavity is nearly triple as well as mean concave.points (the standard error is also much higher for the mean concave.points)
- Mean symmetry is fairly similar across both types of tissue althogh malignant has a higher standard error
- Fractical dimension is slightly higher for malignant than benign tissue
- Most of the standard errors are fairly similar which is interesting because it gives stronger evidence that the features with higher means for malignant will likely have higher means and could be used as an indicator of whether the tissue is benign or malignant based on the average of the three most extreme points

### Basic Distributions Separated by Tissue Type

```{r}
# create ordered levels and a reversed palette
levels_diag <- levels(factor(df$diagnosis))         # preserve factor ordering
pal <- rev(scales::hue_pal()(length(levels_diag)))  # reversed palette
names(pal) <- levels_diag    
```

#### Radius

```{r}
# Basic distributions of these variables
ggplot(df) + 
  geom_histogram(aes(x = radius_worst, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  geom_vline(data= stats_worst, aes(xintercept = mean_radius, color = diagnosis), 
             linetype = "dashed") + 
  geom_vline(data= stats_worst, aes(xintercept = median_radius, color = diagnosis), 
             linetype = "solid") + 
  labs(x = "Radius (worst)", y = "Count",
       title = "Distribution of the Worst Radius by Diagnosis")

```
The above graph shows the worst radius based on whether the tissue is benign or malignant. The mean values are in the dashed lines and the median values are the solid lines.

We also see that the benign distribution has a mean very close to the median, whereas the malignant distribution has a mean which is greater than the median due to outliers.

Both look fairly normally distributed, but we may want to address the outliers in the malignant distribution.

#### Texture
```{r}
# Basic distributions of these variables
ggplot(df) + 
  geom_histogram(aes(x = texture_worst, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  geom_vline(data= stats_worst, aes(xintercept = mean_texture, color = diagnosis), 
             linetype = "dashed") + 
  geom_vline(data= stats_worst, aes(xintercept = median_texture, color = diagnosis), 
             linetype = "solid") + 
  labs(x = "Texture (worst)", y = "Count",
       title = "Distribution of the Worst Texture by Diagnosis")
```

These distributins have a fairly similar shape and both look roughly normal although there are some potential outliers for the malignant tissue. Transformation is likely not needed for this distribution unless we want to correct for outliers.

#### Perimeter
```{r}
# Basic distributions of these variables
ggplot(df) + 
  geom_histogram(aes(x = perimeter_worst, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  geom_vline(data= stats_worst, aes(xintercept = mean_perimeter, color = diagnosis), 
             linetype = "dashed") + 
  geom_vline(data= stats_worst, aes(xintercept = median_perimeter, color = diagnosis), 
             linetype = "solid") + 
  labs(x = "Perimeter (worst)", y = "Count",
       title = "Distribution of the Worst Perimeter by Diagnosis")

```

For Perimeter we notice that malignant tissue is more right-skewed based on the fact that the mean is a bit higher than the median. Although a transformation could be useful to correct for this asymmetry, we might not want to transform the distributions since the malignant distribution is fairly normal.

#### Area
```{r}
# Basic distributions of these variables
ggplot(df) + 
  geom_histogram(aes(x = area_worst, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  geom_vline(data= stats_worst, aes(xintercept = mean_area, color = diagnosis), 
             linetype = "dashed") + 
  geom_vline(data= stats_worst, aes(xintercept = median_area, color = diagnosis), 
             linetype = "solid") + 
  labs(x = "Area (worst)", y = "Count",
       title = "Distribution of the Worst Area by Diagnosis")
```
This is one of the first variables where area is very differently distributed between malignant and benign tissue. It might be worth further exploring area for this reason, especially given how strong of a right skew the malignant tissue has.

#### Smoothness
```{r}
# Basic distributions of these variables
ggplot(df) + 
  geom_histogram(aes(x = smoothness_worst, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  geom_vline(data= stats_worst, aes(xintercept = mean_smoothness, color = diagnosis), 
             linetype = "dashed") + 
  geom_vline(data= stats_worst, aes(xintercept = median_smoothness, color = diagnosis), 
             linetype = "solid") + 
  labs(x = "Smoothness (worst)", y = "Count",
       title = "Distribution of the Worst Smoothness by Diagnosis")
```

This distribution is fairly similar across both tissues although malignant does tend to have a higher mean and medina value of smoothness.

#### Compactness
```{r}
# Basic distributions of these variables
ggplot(df) + 
  geom_histogram(aes(x = compactness_worst, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  geom_vline(data= stats_worst, aes(xintercept = mean_compactness, color = diagnosis), 
             linetype = "dashed") + 
  geom_vline(data= stats_worst, aes(xintercept = median_compactness, color = diagnosis), 
             linetype = "solid") + 
  labs(x = "Compactness (worst)", y = "Count",
       title = "Distribution of the Worst Compactness by Diagnosis")
```

Similarly to area, the compactness is much more spread out for malignant tissue and has a stronger presence of outliers. However, the benign tissue is also right skewed a bit. Applying a transformation to both of these distributions might help to address the normality assumptions. 

#### Concavity
```{r}
# Basic distributions of these variables
ggplot(df) + 
  geom_histogram(aes(x = concavity_worst, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  geom_vline(data= stats_worst, aes(xintercept = mean_concavity, color = diagnosis), 
             linetype = "dashed") + 
  geom_vline(data= stats_worst, aes(xintercept = median_concavity, color = diagnosis), 
             linetype = "solid") + 
  labs(x = "Concavity (worst)", y = "Count",
       title = "Distribution of the Worst Concavity by Diagnosis")
```

Again, both malignant and benign are right skewed but benign has a stronger right skew in this distribution. Applying a transformation will be usefult o address the violation of normality assumptions.

#### Texture
```{r}
# Basic distributions of these variables
ggplot(df) + 
  geom_histogram(aes(x = concave.points_worst, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  geom_vline(data= stats_worst, aes(xintercept = mean_concave.points, color = diagnosis), 
             linetype = "dashed") + 
  geom_vline(data= stats_worst, aes(xintercept = median_concave.points, color = diagnosis), 
             linetype = "solid") + 
  labs(x = "Concave Points (worst)", y = "Count",
       title = "Distribution of the Worst Concave Points by Diagnosis")

```

The mean concave points are both fairly normally distributed with the malignant tissue having a much higher mean an median when comparing the types of tissue which could be something to explore further.

#### Symmetry
```{r}
# Basic distributions of these variables
ggplot(df) + 
  geom_histogram(aes(x = symmetry_worst, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  geom_vline(data= stats_worst, aes(xintercept = mean_symmetry, color = diagnosis), 
             linetype = "dashed") + 
  geom_vline(data= stats_worst, aes(xintercept = median_symmetry, color = diagnosis), 
             linetype = "solid") + 
  labs(x = "Symmetry (worst)", y = "Count",
       title = "Distribution of the Worst Symmetry by Diagnosis")

```
Symmetry has closer median values but malignant tissue has several outliers leading to a right skew in the distribution.

#### Fractal Dimension
```{r}
# Basic distributions of these variables
ggplot(df) + 
  geom_histogram(aes(x = fractal_dimension_worst, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  geom_vline(data= stats_worst, aes(xintercept = mean_fractal_dimension, 
                                    color = diagnosis), 
             linetype = "dashed") + 
  geom_vline(data= stats_worst, aes(xintercept = median_fractal_dimension, 
                                    color = diagnosis), 
             linetype = "solid") + 
  labs(x = "Fractal Dimension (worst)", y = "Count",
       title = "Distribution of the Worst Fractal Dimension by Diagnosis")
```
Both of these distributions are right skewed, but they are fairly close in terms of how they overal over each other. Transforming this feature might be a good idea to address the normality assumptions.

### Quantifying the distance of the worst from the mean

```{r}
# Building a dataframe to quantify the distance between the worst and the mean
df <- df |>
  mutate(
    radius_worst_dist = radius_worst - radius_mean,
    radius_worst_stand = radius_worst_dist / radius_se,
    texture_worst_dist = texture_worst - texture_mean,
    texture_worst_stand = texture_worst_dist / texture_se, 
    perimeter_worst_dist = perimeter_worst - perimeter_mean,
    perimeter_worst_stand = 
      perimeter_worst_dist / perimeter_se,
    area_worst_dist = area_worst - area_mean,
    area_worst_stand = area_worst_dist / area_se, 
    smoothness_worst_dist = 
      smoothness_worst - smoothness_mean,
    smoothness_worst_stand = 
      smoothness_worst_dist / smoothness_se,
    compactness_worst_dist = 
      compactness_worst - compactness_mean,
    compactness_worst_stand = 
      compactness_worst_dist / compactness_se, 
    concavity_worst_dist = 
      concavity_worst - concavity_mean,
    concavity_worst_stand = 
     concavity_worst_dist / concavity_se,
    concave.points_worst_dist = 
      concave.points_worst - concave.points_mean,
    concave.points_worst_stand = 
      concave.points_worst_dist / concave.points_se, 
    symmetry_worst_dist = 
      symmetry_worst - symmetry_mean,
    symmetry_worst_stand = 
      symmetry_worst_dist / symmetry_se, 
    fractal_dimension_worst_dist = 
       fractal_dimension_worst -  fractal_dimension_mean,
    fractal_dimension_worst_stand = 
       fractal_dimension_worst_dist /  fractal_dimension_se, 
  )

```

# Visualizing Standard Error Boxplots

#### Radius
```{r}
# Visualizing the distances
ggplot(df) + 
  geom_boxplot(aes(x = radius_worst_dist, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  labs(x = "Radius Distance (worst)", y = "Count",
       title = "Distribution of the Radius Distance by Diagnosis")

# Visualizing the standard errors
ggplot(df) + 
  geom_boxplot(aes(x = radius_worst_stand, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  labs(x = "Radius Standard Errors (worst)", y = "Count",
       title = "Distribution of the Radius Standard Errors by Diagnosis")
```
#### Texture
```{r}
# Visualizing the distances
ggplot(df) + 
  geom_boxplot(aes(x = texture_worst_dist, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  labs(x = "Texture Distance (worst)", y = "Count",
       title = "Distribution of the Texture Distance by Diagnosis")

# Visualizing the standard errors
ggplot(df) + 
  geom_boxplot(aes(x = texture_worst_stand, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  labs(x = "Texture Standard Errors (worst)", y = "Count",
       title = "Distribution of the Texture Standard Errors by Diagnosis")
```

#### Perimeter
```{r}
# Visualizing the distances
ggplot(df) + 
  geom_boxplot(aes(x = perimeter_worst_dist, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  labs(x = "Perimeter Distance (worst)", y = "Count",
       title = "Distribution of the Perimeter Distance by Diagnosis")

# Visualizing the standard errors
ggplot(df) + 
  geom_boxplot(aes(x = perimeter_worst_stand, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  labs(x = "Perimeter Standard Errors (worst)", y = "Count",
       title = "Distribution of the Perimeter Standard Errors by Diagnosis")
```

#### Area
```{r}
# Visualizing the distances
ggplot(df) + 
  geom_boxplot(aes(x = area_worst_dist, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  labs(x = "Area Distance (worst)", y = "Count",
       title = "Distribution of the Area Distance by Diagnosis")

# Visualizing the standard errors
ggplot(df) + 
  geom_boxplot(aes(x = area_worst_stand, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  labs(x = "Area Standard Errors (worst)", y = "Count",
       title = "Distribution of the Area Standard Errors by Diagnosis")
```

#### Smoothness
```{r}
# Visualizing the distances
ggplot(df) + 
  geom_boxplot(aes(x = smoothness_worst_dist, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  labs(x = "Smoothness Distance (worst)", y = "Count",
       title = "Distribution of the Smoothness Distance by Diagnosis")

# Visualizing the standard errors
ggplot(df) + 
  geom_boxplot(aes(x = smoothness_worst_stand, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  labs(x = "Smoothness Standard Errors (worst)", y = "Count",
       title = "Distribution of the Smoothness Standard Errors by Diagnosis")
```

#### Compactness
```{r}
# Visualizing the distances
ggplot(df) + 
  geom_boxplot(aes(x = compactness_worst_dist, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  labs(x = "Compactness Distance (worst)", y = "Count",
       title = "Distribution of the Compactness Distance by Diagnosis")

# Visualizing the standard errors
ggplot(df) + 
  geom_boxplot(aes(x = compactness_worst_stand, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  labs(x = "Compactness Standard Errors (worst)", y = "Count",
       title = "Distribution of the Compactness Standard Errors by Diagnosis")
```

#### Concavity
```{r}
# Visualizing the distances
ggplot(df) + 
  geom_boxplot(aes(x = concavity_worst_dist, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  labs(x = "Concavity Distance (worst)", y = "Count",
       title = "Distribution of the Concavity Distance by Diagnosis")

# Visualizing the standard errors
ggplot(df) + 
  geom_boxplot(aes(x = concavity_worst_stand, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  labs(x = "Concavity Standard Errors (worst)", y = "Count",
       title = "Distribution of the Concavity Standard Errors by Diagnosis")
```


#### Concave Points
```{r}
# Visualizing the distances
ggplot(df) + 
  geom_boxplot(aes(x = concave.points_worst_dist, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  labs(x = "Concave Points Distance (worst)", y = "Count",
       title = "Distribution of the Concave Points Distance by Diagnosis")

# Visualizing the standard errors
ggplot(df) + 
  geom_boxplot(aes(x = concave.points_worst_stand, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  labs(x = "Concave Points Standard Errors (worst)", y = "Count",
       title = "Distribution of the Concave Points Standard Errors by Diagnosis")
```

#### Symmetry
```{r}
# Visualizing the distances
ggplot(df) + 
  geom_boxplot(aes(x = symmetry_worst_dist, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  labs(x = "Symmetry Distance (worst)", y = "Count",
       title = "Distribution of the Symmetry Distance by Diagnosis")

# Visualizing the standard errors
ggplot(df) + 
  geom_boxplot(aes(x = symmetry_worst_stand, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  labs(x = "Symmetry Standard Errors (worst)", y = "Count",
       title = "Distribution of the Symmetry Standard Errors by Diagnosis")
```

#### Fractal Dimension
```{r}
# Visualizing the distances
ggplot(df) + 
  geom_boxplot(aes(x = fractal_dimension_worst_dist, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  labs(x = "Fractal Dimension Distance (worst)", y = "Count",
       title = "Distribution of the Fractal Dimension Distance by Diagnosis")

# Visualizing the standard errors
ggplot(df) + 
  geom_boxplot(aes(x = fractal_dimension_worst_stand, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  labs(x = "Fractal Dimension Standard Errors (worst)", y = "Count",
       title = "Distribution of the Fractal Dimension Standard Errors by Diagnosis")
```

