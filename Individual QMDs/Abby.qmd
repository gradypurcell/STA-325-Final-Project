
```{r}
library(here)
library(glmnet)
library(dplyr)

data <- read.csv(here("Data", "data.csv"))

# remove column X - irrelevant to analyses
data <- data %>% select(-X)

df <- data.frame(data)

```

## Lasso-Penalized Logistic Regression

```{r}
# 1 = malignant, 0 = benign
df$diagnosis <- ifelse(df$diagnosis == "M", 1, 0)

log_model <- glm(diagnosis ~ ., data = df, family = binomial)

# summary(log_model)
# using all 30 predictors -> multicollinearity

# instead use LASSO regression to actually perform variable selection 

df <- df[ , !names(df) %in% c("id", "X", "Unnamed..32") ] # remove id columns

X <- model.matrix(diagnosis ~ ., data = df)[, -1]
y <- df$diagnosis

set.seed(123) 
n <- nrow(X)
train_idx <- sample(seq_len(n), size = 0.8 * n)

X_train <- X[train_idx, ]
X_test  <- X[-train_idx, ]
y_train <- y[train_idx]
y_test  <- y[-train_idx]

cvfit <- cv.glmnet(
  x = X_train,
  y = y_train,
  family = "binomial",
  alpha = 1,        # LASSO
  nfolds = 5        # 5-fold CV
)

plot(cvfit) 

prob_test <- predict(cvfit, newx = X_test, s = "lambda.min", type = "response")

# Turn into class predictions
pred_test <- ifelse(prob_test > 0.5, 1, 0)

# evaluate diff thresholds to reduce chances of false negatives
# threshold <- 0.3
# pred_test_adj <- ifelse(prob_test > threshold, 1, 0)

# table(pred_test_adj, y_test)

# Accuracy
mean(pred_test == y_test)

# 98% accuracy on test data

```


```{r}
# determining thresholds

library(caret)

evaluate_threshold <- function(prob, truth, threshold) {
  pred <- ifelse(prob > threshold, 1, 0)
  cm <- confusionMatrix(
    factor(pred, levels = c(0,1)),
    factor(truth, levels = c(0,1)),
    mode = "everything"
  )
  tibble(
    threshold = threshold,
    accuracy = cm$overall["Accuracy"],
    sensitivity = cm$byClass["Sensitivity"],   # True Positive Rate
    specificity = cm$byClass["Specificity"],   # True Negative Rate
    fn = cm$table["1","0"],  # False negatives: predicted benign, truth malignant
    fp = cm$table["0","1"]   # False positives
  )
}

thresholds <- seq(0.05, 0.50, by = 0.01)

results <- bind_rows(
  lapply(thresholds, evaluate_threshold, prob = prob_test, truth = y_test)
)

print(results)

best <- results %>% filter(sensitivity >= 0.95) %>% slice(1)
best
```
Most ideal threshold = 0.19
Still maintains an accuracy of 97% with sensitivity of 95%

```{r}
threshold <- 0.19
pred_test_adj <- ifelse(prob_test > threshold, 1, 0)

confusionMatrix(
  factor(pred_test_adj, levels = c(0,1)),
  factor(y_test, levels = c(0,1)),
  mode = "everything"
)
```


```{r}
# showing which predictors are the most important

coef(cvfit, s = "lambda.min")

# computing the confusion matrix

table(pred_test, y_test)
```

Based on the LASSO regression, the model predicted 1 false negative: gave 0 (benign) when the actual was malignant (1). 

Predictors that are the most telling: 
The strongest ones that increase the log odds of a tumor being malignant- 
- concave points mean, smoothness_se
The strongest ones that decrease the log odds of tumor being malignant (more likely to be benign)
- compactness mean, fractal dimension se, compactness se

Malignant tumors tend to have more irregular, concave, asymmetric nuclei; worse ones have more abnormalities and there's high variation 
Benign tumors tend to be more uniform and have lower fractal dimension variability

## EDA for Lasso Regression Model

```{r}
library(ggplot2)
library(tidyverse)

df_long <- df %>%
  pivot_longer(cols = -diagnosis, names_to = "variable", values_to = "value")

ggplot(df_long, aes(value)) +
  geom_histogram(bins = 30, fill = "gray70", color = "black") +
  facet_wrap(~variable, scales = "free") +
  labs(title = "Distribution of Predictor Variables") +
  theme_minimal()

```


```{r}
library(corrplot)
corr_matrix <- cor(df %>% select(-diagnosis))

corrplot(corr_matrix,
         method = "color",
         tl.cex = 0.6,
         number.cex = 0.5,
         title = "Correlation Heatmap of Predictors",
         mar=c(0,0,2,0))
```

Interpretation of this plot: Strong patterns of correlation and multicollinearity in the data. As seen in the top left block for "mean", the variables (radius_mean, texture_mean, perimeter_mean, area_mean, compactness_mean, concavity_mean, concave.points_mean) are strongly correlated b/n 0.7-0.9 as indicated by the dark blue color. Lasso will probably select only a few predictors from this cluster and shrink the rest of the coefficients to zero due to redudancy. For "se", seem to be moderately correlated. For "worst", strongest correlations appear near the bottom right for variables radius_worst, area_worst, concavity, concave.points, and perimeter. 



## Classification Trees

```{r}
library(rpart)

df2 <- read.csv("data.csv")

# 2. Remove ID and empty column
df2 <- df2[ , !names(df) %in% c("id", "Unnamed..32") ]


df$diagnosis <- factor(df2$diagnosis, levels = c("B", "M"))

```

```{r}
set.seed(123)
n <- nrow(df)
train_idx <- sample(seq_len(n), size = 0.8 * n)

train <- df[train_idx, ]
test  <- df[-train_idx, ]

tree_model <- rpart(
  diagnosis ~ .,
  data = train,
  method = "class",
  control = rpart.control(cp = 0.01)   # complexity parameter
)

# evaluate accuracy of tree on testing data

pred <- predict(tree_model, newdata = test, type = "class")

cm <- table(Predicted = pred, Actual = test$diagnosis)
cm

accuracy <- sum(diag(cm)) / sum(cm)
accuracy
# 92% accuracy
```
Could try pruning the tree for even better accuracy

## Bagging 

```{r}
library(randomForest)

bag_model <- randomForest(
  diagnosis ~ ., 
  data = train,
  mtry = ncol(train) - 1,   # mtry = all predictors = bagging
  ntree = 500
)

bag_pred <- predict(bag_model, test)
mean(bag_pred == test$diagnosis)
```
96% accuracy with bagging- which is higher

## Random Forests
- should provide an improvement over bagged trees as it decorrelates them and reduces variance 

```{r}
rf_model <- randomForest(
  diagnosis ~ ., 
  data = train,
  mtry = sqrt(ncol(train) - 1), 
  ntree = 500,
  importance = TRUE
)

rf_pred <- predict(rf_model, test)
mean(rf_pred == test$diagnosis)

```
Gives accuracy of ~95%

# Tumor Image

```{r}
m_tumor <- df %>%
  filter(diagnosis == "1") %>%
  slice(1)

m_tumor
```
```{r}
set.seed(123)

# Use features from that single observation
radius_mean       <- m_tumor$radius_mean        # overall size
concavity_worst   <- m_tumor$concavity_worst    # bumpiness / irregularity

# number of points on the surface
n_points <- 4000

# Sample points on a sphere
phi   <- runif(n_points, 0, pi)        # polar angle
theta <- runif(n_points, 0, 2 * pi)    # azimuthal angle

# Base radius and bumps
base_r <- radius_mean
bump_sd <- concavity_worst * 3         # tweak factor to change roughness

# radius for each point (base + random bumps, keep positive)
r <- pmax(
  0.1,
  rnorm(n_points, mean = base_r, sd = bump_sd)
)

# Convert spherical to Cartesian coordinates
x <- r * sin(phi) * cos(theta)
y <- r * sin(phi) * sin(theta)
z <- r * cos(phi)

# 3D interactive plot
plot_ly(
  tumor_points,
  x = ~x,
  y = ~y,
  z = ~z,
  type = "scatter3d",
  mode = "markers",
  marker = list(
    size = 2,
    opacity = 0.7,
    color = ~radius,       # color by local radius
    colorscale = "Reds"
  )
) %>%
  layout(
    title = paste0("Simulated 3D Malignant Tumor"),
    scene = list(
      xaxis = list(title = "X (mm)"),
      yaxis = list(title = "Y (mm)"),
      zaxis = list(title = "Z (mm)")
    )
  )
```

```{r}
library(dplyr)
library(plot3D)

# pick one malignant and one benign case
malignant_tumor <- df %>%
  filter(diagnosis == 1) %>%    # 1 = malignant
  slice(1)

benign_tumor <- df %>%
  filter(diagnosis == 0) %>%    # 0 = benign
  slice(1)

malignant_tumor
benign_tumor

```

```{r}
simulate_tumor <- function(radius_mean, concavity_worst,
                           n_points = 4000,
                           x_offset = 0) {
  set.seed(123)  # for reproducibility

  # random directions on the sphere
  phi   <- runif(n_points, 0, pi)
  theta <- runif(n_points, 0, 2 * pi)

  base_r  <- radius_mean
  bump_sd <- concavity_worst * 3  # bumpiness

  r <- pmax(0.1, rnorm(n_points, mean = base_r, sd = bump_sd))

  x <- r * sin(phi) * cos(theta) + x_offset
  y <- r * sin(phi) * sin(theta)
  z <- r * cos(phi)

  data.frame(x = x, y = y, z = z, radius = r)
}

```

```{r}
# features for each tumor
rm_mal <- malignant_tumor$radius_mean
cw_mal <- malignant_tumor$concavity_worst

rm_ben <- benign_tumor$radius_mean
cw_ben <- benign_tumor$concavity_worst

# offsets so they are side-by-side
offset <- max(rm_mal, rm_ben) * 1.8

tumor_mal <- simulate_tumor(rm_mal, cw_mal, x_offset = -offset)
tumor_ben <- simulate_tumor(rm_ben, cw_ben, x_offset =  offset)

tumor_mal$type <- "Malignant"
tumor_ben$type <- "Benign"

tumors <- rbind(tumor_mal, tumor_ben)
```

```{r}
# color by type
cols <- ifelse(tumors$type == "Malignant", "red", "deepskyblue3")

scatter3D(
  x = tumors$x,
  y = tumors$y,
  z = tumors$z,
  col = cols,
  colvar = NULL,        # we handle colors manually
  pch = 16,
  cex = 0.5,
  main = "Simulated 3D Tumors: Malignant vs Benign",
  xlab = "X (mm)",
  ylab = "Y (mm)",
  zlab = "Z (mm)",
  theta = 40,
  phi   = 20,
  bty = "g",
  ticktype = "simple"
)

legend(
  "topright",
  col = c("red", "deepskyblue3"),
  pch = 16,
  legend = c("Malignant (diagnosis = 1)", "Benign (diagnosis = 0)"),
  cex = 0.6,          # smaller text + box
  pt.cex = 0.6,       # smaller dot size
  bty = "n"           # optional: remove box border
)

```

