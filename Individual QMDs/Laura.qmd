# Laura's QMD Work

## Reading in the Data

```{r}
# Loading the packages
library(tidyverse)
library(ggplot2)
library(dplyr)


# Loading the data
df <- read.csv("data.csv")
df <- df[, -33]
```

## EDA for Mean

Mean: mean of all values 


### Table Comparing Benign vs Malignant
```{r}
# Creating a new dataframe
stats_mean <- df |>
  group_by(diagnosis) |>
  summarise(
    count = n(),
    mean_radius = mean(radius_mean),
    median_radius = median(radius_mean),
    se_radius = sd(radius_mean),
    mean_texture = mean(texture_mean),
    median_texture = median(texture_mean),
    se_texture = sd(texture_mean),
    mean_perimeter = mean(perimeter_mean),
    median_perimeter = median(perimeter_mean),
    se_perimeter = sd(perimeter_mean),
    mean_area = mean(area_mean),
    median_area = median(area_mean),
    se_area = sd(area_mean),
    mean_smoothness = mean(smoothness_mean),
    median_smoothness = median(smoothness_mean),
    se_smoothness = sd(smoothness_mean),
    mean_compactness = mean(compactness_mean),
    median_compactness = median(compactness_mean),
    se_compactness = sd(compactness_mean),
    mean_concavity = mean(concavity_mean),
    median_concavity = median(concavity_mean),
    se_concavity = sd(concavity_mean),
    mean_concave.points = mean(concave.points_mean),
    median_concave.points = median(concave.points_mean),
    se_concave.points = sd(concave.points_mean),
    mean_symmetry = mean(symmetry_mean),
    median_symmetry = median(symmetry_mean),
    se_symmetry = sd(symmetry_mean),
    mean_fractal_dimension = mean(fractal_dimension_mean),
    median_fractal_dimension = median(fractal_dimension_mean),
    se_fractal_dimension = sd(fractal_dimension_mean),
  )

# Transposing the dataframe
stats_mean_t <- t(stats_mean)

# Making the diagnosis the column
colnames(stats_mean_t) <- as.character(unlist(stats_mean_t[1, ])) 
stats_mean_t <- stats_mean_t[-1, ]  # remove the first row

stats_mean_t
```

Key Observations
- Malignant nuclei are noticeably larger by radius, perimeter, and area and have more texture variation. 
- Malignant nuclei have deeper concave regions
- The fractal dimensions are similar
- The standard errors for radius, area, and concavity were significantly larger.

### Basic Distributions Separated by Tissue Type

```{r}
# create ordered levels and a reversed palette
levels_diag <- levels(factor(df$diagnosis))         # preserve factor ordering
pal <- rev(scales::hue_pal()(length(levels_diag)))  # reversed palette
names(pal) <- levels_diag    
```

#### Radius

```{r}
# Basic distributions of these variables
ggplot(df) + 
  geom_histogram(aes(x = radius_mean, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  geom_vline(data= stats_mean, aes(xintercept = mean_radius, color = diagnosis), 
             linetype = "dashed") + 
  geom_vline(data= stats_mean, aes(xintercept = median_radius, color = diagnosis), 
             linetype = "solid") + 
  labs(x = "Radius (mean)", y = "Count",
       title = "Distribution of the Mean Radius by Diagnosis")

```
The above graph shows the mean radius based on whether the tissue is benign or malignant. The mean values are in the dashed lines and the median values are the solid lines.

We also see that the benign distribution has a mean very close to the median, whereas the malignant distribution has a mean which is greater than the median due to outliers.

Both look fairly normally distributed, but we may want to address the outliers in the malignant distribution.

#### Texture
```{r}
# Basic distributions of these variables
ggplot(df) + 
  geom_histogram(aes(x = texture_mean, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  geom_vline(data= stats_mean, aes(xintercept = mean_texture, color = diagnosis), 
             linetype = "dashed") + 
  geom_vline(data= stats_mean, aes(xintercept = median_texture, color = diagnosis), 
             linetype = "solid") + 
  labs(x = "Texture (mean)", y = "Count",
       title = "Distribution of the Mean Texture by Diagnosis")
```

These distributins have a fairly similar shape and both look roughly normal although there are some potential outliers for the malignant tissue. Transformation is likely not needed for this distribution unless we want to correct for outliers.

#### Perimeter
```{r}
# Basic distributions of these variables
ggplot(df) + 
  geom_histogram(aes(x = perimeter_mean, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  geom_vline(data= stats_mean, aes(xintercept = mean_perimeter, color = diagnosis), 
             linetype = "dashed") + 
  geom_vline(data= stats_mean, aes(xintercept = median_perimeter, color = diagnosis), 
             linetype = "solid") + 
  labs(x = "Perimeter (mean)", y = "Count",
       title = "Distribution of the Mean Perimeter by Diagnosis")

```

For Perimeter we notice that malignant tissue is more right-skewed based on the fact that the mean is a bit higher than the median. Although a transformation could be useful to correct for this asymmetry, we might not want to transform the distributions since the malignant distribution is fairly normal.

#### Area
```{r}
# Basic distributions of these variables
ggplot(df) + 
  geom_histogram(aes(x = area_mean, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  geom_vline(data= stats_mean, aes(xintercept = mean_area, color = diagnosis), 
             linetype = "dashed") + 
  geom_vline(data= stats_mean, aes(xintercept = median_area, color = diagnosis), 
             linetype = "solid") + 
  labs(x = "Area (mean)", y = "Count",
       title = "Distribution of the Mean Area by Diagnosis")
```
This is one of the first variables where area is very differently distributed between malignant and benign tissue. It might be worth further exploring area for this reason, especially given how strong of a right skew the malignant tissue has.

#### Smoothness
```{r}
# Basic distributions of these variables
ggplot(df) + 
  geom_histogram(aes(x = smoothness_mean, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  geom_vline(data= stats_mean, aes(xintercept = mean_smoothness, color = diagnosis), 
             linetype = "dashed") + 
  geom_vline(data= stats_mean, aes(xintercept = median_smoothness, color = diagnosis), 
             linetype = "solid") + 
  labs(x = "Smoothness (mean)", y = "Count",
       title = "Distribution of the Mean Smoothness by Diagnosis")
```

This distribution is fairly similar across both tissues although malignant does tend to have a higher mean and medina value of smoothness.

#### Compactness
```{r}
# Basic distributions of these variables
ggplot(df) + 
  geom_histogram(aes(x = compactness_mean, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  geom_vline(data= stats_mean, aes(xintercept = mean_compactness, color = diagnosis), 
             linetype = "dashed") + 
  geom_vline(data= stats_mean, aes(xintercept = median_compactness, color = diagnosis), 
             linetype = "solid") + 
  labs(x = "Compactness (mean)", y = "Count",
       title = "Distribution of the Mean Compactness by Diagnosis")
```

Similarly to area, the compactness is much more spread out for malignant tissue and has a stronger presence of outliers. However, the benign tissue is also right skewed a bit. Applying a transformation to both of these distributions might help to address the normality assumptions. 

#### Concavity
```{r}
# Basic distributions of these variables
ggplot(df) + 
  geom_histogram(aes(x = concavity_mean, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  geom_vline(data= stats_mean, aes(xintercept = mean_concavity, color = diagnosis), 
             linetype = "dashed") + 
  geom_vline(data= stats_mean, aes(xintercept = median_concavity, color = diagnosis), 
             linetype = "solid") + 
  labs(x = "Concavity (mean)", y = "Count",
       title = "Distribution of the Mean Concavity by Diagnosis")
```

Again, both malignant and benign are right skewed but benign has a stronger right skew in this distribution. Applying a transformation will be usefult o address the violation of normality assumptions.

#### Texture
```{r}
# Basic distributions of these variables
ggplot(df) + 
  geom_histogram(aes(x = concave.points_mean, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  geom_vline(data= stats_mean, aes(xintercept = mean_concave.points, color = diagnosis), 
             linetype = "dashed") + 
  geom_vline(data= stats_mean, aes(xintercept = median_concave.points, color = diagnosis), 
             linetype = "solid") + 
  labs(x = "Concave Points (mean)", y = "Count",
       title = "Distribution of the Mean Concave Points by Diagnosis")

```

The mean concave points are both fairly normally distributed with the malignant tissue having a much higher mean an median when comparing the types of tissue which could be something to explore further.

#### Symmetry
```{r}
# Basic distributions of these variables
ggplot(df) + 
  geom_histogram(aes(x = symmetry_mean, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  geom_vline(data= stats_mean, aes(xintercept = mean_symmetry, color = diagnosis), 
             linetype = "dashed") + 
  geom_vline(data= stats_mean, aes(xintercept = median_symmetry, color = diagnosis), 
             linetype = "solid") + 
  labs(x = "Symmetry (mean)", y = "Count",
       title = "Distribution of the Mean Symmetry by Diagnosis")

```
Symmetry has closer median values but malignant tissue has several outliers leading to a right skew in the distribution.

#### Fractal Dimension
```{r}
# Basic distributions of these variables
ggplot(df) + 
  geom_histogram(aes(x = fractal_dimension_mean, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  geom_vline(data= stats_mean, aes(xintercept = mean_fractal_dimension, 
                                    color = diagnosis), 
             linetype = "dashed") + 
  geom_vline(data= stats_mean, aes(xintercept = median_fractal_dimension, 
                                    color = diagnosis), 
             linetype = "solid") + 
  labs(x = "Fractal Dimension (mean)", y = "Count",
       title = "Distribution of the Mean Fractal Dimension by Diagnosis")
```
Both of these distributions are right skewed, but they are fairly close in terms of how they overal over each other. Transforming this feature might be a good idea to address the normality assumptions.

```{r}
corr_matrix <- df |> 
  select(ends_with("_mean")) |> 
  cor()

corrplot::corrplot(corr_matrix, method = "color", type = "upper", tl.cex = 0.7)
```

```{r}
corr_matrix <- df |> 
  select(ends_with("_worst")) |> 
  cor()

corrplot::corrplot(corr_matrix, method = "color", type = "upper", tl.cex = 0.7)

corr_matrix
```

```{r}

corr_matrix <- df |>
  select("concave.points_mean", "radius_se", "smoothness_se", "radius_worst", "texture_worst", "smoothness_worst", "concavity_worst", "concave.points_worst", "symmetry_worst") |> 
  cor()

corrplot::corrplot(corr_matrix, method = "color", type = "upper", tl.cex = 0.7)

corr_matrix
diag(corr_matrix) <- 0  # remove diagonal

weak_pairs <- corr_matrix |>
  as.data.frame() |>
  rownames_to_column("var1") |>
  pivot_longer(-var1, names_to = "var2", values_to = "cor") |>
  filter(var1 < var2,
         cor > -0.2,
         cor < 0.2)

weak_pairs
```



```{r}
pairs(df[, c("radius_mean", "texture_mean", "perimeter_mean", "area_mean", "smoothness_mean")])
```


SUPPORT VECTOR MACHINES


```{r}
#install.packages('e1071') 
#install.packages('caTools')
#install.packages('ggplot2')
#install.packages('caret')

library(caret)
library(e1071) 
library(caTools)
library(ggplot2)
```

```{r}
#update.packages("caTools", checkBuilt = TRUE)
```



```{r}
library(caTools)
set.seed(123)
split <- sample.split(df, SplitRatio = 0.8)
training <- subset(df, split == TRUE)
test <- subset(df, split == FALSE)

training$diagnosis <- as.factor(training$diagnosis)
test$diagnosis <- as.factor(test$diagnosis)


X_train = training[,-2]
y_train = training[,2]
X_test = test[,-2]
y_test = test[,2]
classifier <- svm(diagnosis ~ ., data = training, type = 'C-classification', kernel = 'radial', gamma = 0.1)
y_pred <- predict(classifier, newdata = test)

table(test$diagnosis, y_pred)

accuracy <- sum(diag(table(test$diagnosis, y_pred))) / sum(table(test$diagnosis, y_pred))
cat("Accuracy: ", accuracy)

confusionMatrix(table(test$diagnosis, y_pred))
```
```{r}
classifier
```

```{r}
library(caTools)
set.seed(123)
split <- sample.split(df, SplitRatio = 0.8)
training <- subset(df, split == TRUE)
test <- subset(df, split == FALSE)

training$diagnosis <- as.factor(training$diagnosis)
test$diagnosis <- as.factor(test$diagnosis)


X_train = training[,-2]
y_train = training[,2]
X_test = test[,-2]
y_test = test[,2]
classifier <- svm(diagnosis ~ .^2, data = training, type = 'C-classification', kernel = 'radial', gamma = 0.1)
y_pred <- predict(classifier, newdata = test)

table(test$diagnosis, y_pred)

accuracy <- sum(diag(table(test$diagnosis, y_pred))) / sum(table(test$diagnosis, y_pred))
cat("Accuracy: ", accuracy)

confusionMatrix(table(test$diagnosis, y_pred))
```


```{r}
log_model <- glm(diagnosis ~ ., 
                 data = training, 
                 family = binomial)

# Predictions (probabilities)
prob_pred <- predict(log_model, newdata = test, type = "response")

# Convert probabilities → class labels (assumes "M" = positive class)
y_pred <- ifelse(prob_pred > 0.5, "M", "B")
y_pred <- factor(y_pred, levels = levels(test$diagnosis))

# Confusion matrix
cm <- table(test$diagnosis, y_pred)
print(cm)

# Accuracy
accuracy <- sum(diag(cm)) / sum(cm)
cat("Accuracy:", accuracy, "\n")

# caret confusion matrix (better stats)
confusionMatrix(y_pred, test$diagnosis)
```

```{r}
log_model <- glm(diagnosis ~ .^2, 
                 data = training, 
                 family = binomial)

# Predictions (probabilities)
prob_pred <- predict(log_model, newdata = test, type = "response")

# Convert probabilities → class labels (assumes "M" = positive class)
y_pred <- ifelse(prob_pred > 0.5, "M", "B")
y_pred <- factor(y_pred, levels = levels(test$diagnosis))

# Confusion matrix
cm <- table(test$diagnosis, y_pred)
print(cm)

# Accuracy
accuracy <- sum(diag(cm)) / sum(cm)
cat("Accuracy:", accuracy, "\n")

# caret confusion matrix (better stats)
confusionMatrix(y_pred, test$diagnosis)
```

```{r}
library(randomForest)
library(caret)

# Fit random forest (NO family=binomial)
rf_model <- randomForest(diagnosis ~ ., data = training)

# Predict probabilities for class "M" (positive class)
prob_pred <- predict(rf_model, newdata = test, type = "prob")[, "M"]

# Convert probabilities to class labels
y_pred <- ifelse(prob_pred > 0.5, "M", "B")
y_pred <- factor(y_pred, levels = levels(test$diagnosis))

# Confusion matrix
cm <- table(Actual = test$diagnosis, Predicted = y_pred)
print(cm)

# Accuracy
accuracy <- sum(diag(cm)) / sum(cm)
cat("Accuracy:", accuracy, "\n")

# caret confusion matrix (more detailed metrics)
confusionMatrix(y_pred, test$diagnosis)
```


The Breast Cancer Wisconsin (Diagnostic) Data Set describes characteristics of the cell nuclei of breast masses. The dataset consists of the mean, standard error and "worst" or largest of these features for these 10 features computred from each image: radium, texture, permimeter, area, smoothness, compactness, concavity, concave points, symmetry, and fractal dimension. The radius is the mean of distances from center to points along the perimeter. Texture is the stadnard deviation of gray-scale values). Perimeter measures the distance along the outside of the mass. Area measures how big the mass is. Smoothness is the local variation in radius lengths. Compactness is caclulated by perimeter^2/area - 1, respresenting how dense or elongated the mass is. Concavity is the severity of concave portions of the contour. Concave points is the number of concave portions of the contour. Symmetry is measured ??. Fractal dimension represents the roughness or complexity of the shape and is calculated by the "coastline approximation" -1. We use the ID number as identificaiton and the diagnosis is either M (malignant) or B (benign) and is our response variable. There are 569 observations, with 357 benign and 212 malignant. (mention how the numbers are okay), and there was no missing data to deal with. 


```{r}
#install.packages("rpart")
#install.packages("rpart.plot")
library(rpart)
library(rpart.plot)

tree_model <- rpart(diagnosis ~ concave.points_mean + radius_se + smoothness_se+ radius_worst + texture_worst+ smoothness_worst+concavity_worst+concave.points_worst+symmetry_worst, data = training, method = "class")

prp(tree_model, extra = 2, fallen.leaves = TRUE, type = 4)


tree_pred <- predict(tree_model, newdata = test, type = "class")
confusionMatrix(tree_pred, test$diagnosis)

```
```{r}
tree_model <- rpart(diagnosis ~ (concave.points_mean + radius_se + smoothness_se+ radius_worst + texture_worst+ smoothness_worst+concavity_worst+concave.points_worst+symmetry_worst)^2, data = training, method = "class")

prp(tree_model, extra = 2, fallen.leaves = TRUE, type = 4)


tree_pred <- predict(tree_model, newdata = test, type = "class")
confusionMatrix(tree_pred, test$diagnosis)
```
```{r}

library(mgcv)      # for gam
library(dplyr)
library(caret)     # confusionMatrix
library(pROC) 
gam_formula <- as.formula(
  "diagnosis ~ 
     s(concave.points_mean) + s(radius_se) + s(smoothness_se) +
     s(radius_worst) + s(texture_worst) + s(smoothness_worst) +
     s(concavity_worst) + s(concave.points_worst) + s(symmetry_worst) +
     # interactions (tensor product smooths)
     ti(radius_worst, concavity_worst) + 
     ti(radius_worst, concave.points_worst) +
     ti(smoothness_worst, concavity_worst) +
     ti(texture_worst, concavity_worst)"
)

# Fit the GAM (binomial family for logistic)
set.seed(42)
gam_model <- gam(gam_formula, data = training, family = binomial(link = "logit"),
                 method = "REML", select = TRUE)

# Model summary (check significant smooths and interactions)
summary(gam_model)
#plot(gam_model, pages = 1, rug = TRUE)  # visual checks

# Predict probabilities on the test set
prob_test <- predict(gam_model, newdata = test, type = "response")

# Convert probabilities to class labels (threshold 0.5; change if you want sensitivity-weighted)
pred_class <- factor(ifelse(prob_test >= 0.5, "M", "B"), levels = levels(training$diagnosis))

# Confusion matrix
conf_mat <- confusionMatrix(pred_class, test$diagnosis, positive = "M")
print(conf_mat)

accuracy <- mean(pred_class == test$diagnosis)

```
```{r}
auc(test$diagnosis, prob_test)
```

```{r}
# R script: Fit EBM via reticulate, predict, confusion matrix
# Run in R (RStudio recommended)

# ----- packages -----
if (!requireNamespace("reticulate", quietly = TRUE)) install.packages("reticulate")
if (!requireNamespace("dplyr", quietly = TRUE)) install.packages("dplyr")
if (!requireNamespace("caret", quietly = TRUE)) install.packages("caret")
if (!requireNamespace("pROC", quietly = TRUE)) install.packages("pROC")

library(reticulate)
library(dplyr)
library(caret)
library(pROC)

# Optionally set a virtualenv or conda env (uncomment & edit if you want)
# reticulate::use_virtualenv("r-reticulate", required = FALSE)
# reticulate::use_condaenv("r-reticulate", required = FALSE)

# ----- ensure python package 'interpret' is available -----
if (!py_module_available("interpret")) {
  message("Python package 'interpret' not found. Installing via py_install('interpret') ...")
  # This will install interpret and dependencies via pip in the active Python env
  reticulate::py_install("interpret", pip = TRUE)
}

# import the package
interpret <- import("interpret")
explainers <- interpret$explainers
EBM <- explainers$ExplainableBoostingClassifier

# ----- Prepare data: predictors X_train/X_test, labels y_train/y_test -----
# Replace these with your actual training/test frames already in R: `training` and `test`
# I assume 'diagnosis' is a factor with levels c("B", "M") as before.

# choose predictors (you can replace/select others)
predictors <- c("concave.points_mean", "radius_se", "smoothness_se",
                "radius_worst", "texture_worst", "smoothness_worst",
                "concavity_worst", "concave.points_worst", "symmetry_worst")

# Ensure predictors exist
stopifnot(all(predictors %in% names(training)))
stopifnot(all(predictors %in% names(test)))

# X (data frames) and y (binary 0/1)
X_train <- training %>% select(all_of(predictors))
X_test  <- test %>% select(all_of(predictors))

# Convert diagnosis to 0/1 (0 = benign "B", 1 = malignant "M")
y_train <- ifelse(as.character(training$diagnosis) == "M", 1L, 0L)
y_test  <- ifelse(as.character(test$diagnosis) == "M", 1L, 0L)

# Convert to Python-friendly objects (pandas DataFrame and numpy array)
pd <- import("pandas")
np <- import("numpy")

X_train_py <- r_to_py(as.data.frame(X_train))
X_test_py  <- r_to_py(as.data.frame(X_test))
y_train_py <- r_to_py(y_train)  # simple numpy array
y_test_py  <- r_to_py(y_test)

# ----- Fit the EBM -----
set.seed(42)
ebm <- EBM()  # you can pass arguments like max_bins, interactions, inner_bags etc.

# Fit can take a bit - this trains an interpretable boosting classifier
message("Fitting EBM (this may take a minute)...")
ebm$fit(X_train_py, y_train_py)

# ----- Predict probabilities & classes on test set -----
# predict_proba returns array[:,0]=prob of class 0, array[:,1]=prob of class 1
probs_test <- ebm$predict_proba(X_test_py)
# convert to R numeric vector of P(M) = column 2
prob_M <- as.numeric(py_to_r(probs_test))      # flatten -> matrix, may need to reshape
# If py_to_r produced a matrix-like list, do:
if (is.matrix(prob_M) || (is.array(prob_M) && length(dim(prob_M)) == 2)) {
  prob_M <- as.numeric(prob_M[,2])  # second column
} else if (is.list(prob_M) && length(prob_M) > 0) {
  # try alternative conversion
  prob_M <- sapply(py_to_r(probs_test), function(x) x[[2]])
}

pred_class <- factor(ifelse(prob_M > 0.5, "M", "B"), levels = levels(training$diagnosis))

# ----- Confusion matrix & accuracy -----
cm <- confusionMatrix(pred_class, test$diagnosis, positive = "M")
print(cm)

accuracy <- mean(pred_class == test$diagnosis)
cat("Accuracy:", round(accuracy, 4), "\n")

# AUC
roc_obj <- roc(response = test$diagnosis, predictor = prob_M, levels = rev(levels(test$diagnosis)))
cat("AUC:", round(auc(roc_obj), 4), "\n")
```


```{r}
library(reticulate)

# import correct module
interpret <- import("interpret")
EBM <- interpret$glassbox$ExplainableBoostingClassifier

# Fit model
ebm <- EBM()
ebm$fit(X_train_py, y_train_py)

# Predict P(M)
probs_test <- ebm$predict_proba(X_test_py)

# extract column 2 = class 1 probability
probs_r <- py_to_r(probs_test)
prob_M <- probs_r[,2]

# convert to class
pred_class <- ifelse(prob_M > 0.5, "M", "B")
pred_class <- factor(pred_class, levels = levels(test$diagnosis))

# evaluate
library(caret)
confusionMatrix(pred_class, test$diagnosis, positive = "M")

```

