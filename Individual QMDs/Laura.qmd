# Laura's QMD Work

## Reading in the Data

```{r}
# Loading the packages
library(tidyverse)
library(ggplot2)
library(dplyr)


# Loading the data
df <- read.csv("data.csv")
df <- df[, -33]
```

## EDA for Mean

Mean: mean of all values 


### Table Comparing Benign vs Malignant
```{r}
# Creating a new dataframe
stats_mean <- df |>
  group_by(diagnosis) |>
  summarise(
    count = n(),
    mean_radius = mean(radius_mean),
    median_radius = median(radius_mean),
    se_radius = sd(radius_mean),
    mean_texture = mean(texture_mean),
    median_texture = median(texture_mean),
    se_texture = sd(texture_mean),
    mean_perimeter = mean(perimeter_mean),
    median_perimeter = median(perimeter_mean),
    se_perimeter = sd(perimeter_mean),
    mean_area = mean(area_mean),
    median_area = median(area_mean),
    se_area = sd(area_mean),
    mean_smoothness = mean(smoothness_mean),
    median_smoothness = median(smoothness_mean),
    se_smoothness = sd(smoothness_mean),
    mean_compactness = mean(compactness_mean),
    median_compactness = median(compactness_mean),
    se_compactness = sd(compactness_mean),
    mean_concavity = mean(concavity_mean),
    median_concavity = median(concavity_mean),
    se_concavity = sd(concavity_mean),
    mean_concave.points = mean(concave.points_mean),
    median_concave.points = median(concave.points_mean),
    se_concave.points = sd(concave.points_mean),
    mean_symmetry = mean(symmetry_mean),
    median_symmetry = median(symmetry_mean),
    se_symmetry = sd(symmetry_mean),
    mean_fractal_dimension = mean(fractal_dimension_mean),
    median_fractal_dimension = median(fractal_dimension_mean),
    se_fractal_dimension = sd(fractal_dimension_mean),
  )

# Transposing the dataframe
stats_mean_t <- t(stats_mean)

# Making the diagnosis the column
colnames(stats_mean_t) <- as.character(unlist(stats_mean_t[1, ])) 
stats_mean_t <- stats_mean_t[-1, ]  # remove the first row

stats_mean_t
```

Key Observations
- Malignant nuclei are noticeably larger by radius, perimeter, and area and have more texture variation. 
- Malignant nuclei have deeper concave regions
- The fractal dimensions are similar
- The standard errors for radius, area, and concavity were significantly larger.

### Basic Distributions Separated by Tissue Type

```{r}
# create ordered levels and a reversed palette
levels_diag <- levels(factor(df$diagnosis))         # preserve factor ordering
pal <- rev(scales::hue_pal()(length(levels_diag)))  # reversed palette
names(pal) <- levels_diag    
```

#### Radius

```{r}
# Basic distributions of these variables
ggplot(df) + 
  geom_histogram(aes(x = radius_mean, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  geom_vline(data= stats_mean, aes(xintercept = mean_radius, color = diagnosis), 
             linetype = "dashed") + 
  geom_vline(data= stats_mean, aes(xintercept = median_radius, color = diagnosis), 
             linetype = "solid") + 
  labs(x = "Radius (mean)", y = "Count",
       title = "Distribution of the Mean Radius by Diagnosis")

```
The above graph shows the mean radius based on whether the tissue is benign or malignant. The mean values are in the dashed lines and the median values are the solid lines.

We also see that the benign distribution has a mean very close to the median, whereas the malignant distribution has a mean which is greater than the median due to outliers.

Both look fairly normally distributed, but we may want to address the outliers in the malignant distribution.

#### Texture
```{r}
# Basic distributions of these variables
ggplot(df) + 
  geom_histogram(aes(x = texture_mean, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  geom_vline(data= stats_mean, aes(xintercept = mean_texture, color = diagnosis), 
             linetype = "dashed") + 
  geom_vline(data= stats_mean, aes(xintercept = median_texture, color = diagnosis), 
             linetype = "solid") + 
  labs(x = "Texture (mean)", y = "Count",
       title = "Distribution of the Mean Texture by Diagnosis")
```

These distributins have a fairly similar shape and both look roughly normal although there are some potential outliers for the malignant tissue. Transformation is likely not needed for this distribution unless we want to correct for outliers.

#### Perimeter
```{r}
# Basic distributions of these variables
ggplot(df) + 
  geom_histogram(aes(x = perimeter_mean, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  geom_vline(data= stats_mean, aes(xintercept = mean_perimeter, color = diagnosis), 
             linetype = "dashed") + 
  geom_vline(data= stats_mean, aes(xintercept = median_perimeter, color = diagnosis), 
             linetype = "solid") + 
  labs(x = "Perimeter (mean)", y = "Count",
       title = "Distribution of the Mean Perimeter by Diagnosis")

```

For Perimeter we notice that malignant tissue is more right-skewed based on the fact that the mean is a bit higher than the median. Although a transformation could be useful to correct for this asymmetry, we might not want to transform the distributions since the malignant distribution is fairly normal.

#### Area
```{r}
# Basic distributions of these variables
ggplot(df) + 
  geom_histogram(aes(x = area_mean, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  geom_vline(data= stats_mean, aes(xintercept = mean_area, color = diagnosis), 
             linetype = "dashed") + 
  geom_vline(data= stats_mean, aes(xintercept = median_area, color = diagnosis), 
             linetype = "solid") + 
  labs(x = "Area (mean)", y = "Count",
       title = "Distribution of the Mean Area by Diagnosis")
```
This is one of the first variables where area is very differently distributed between malignant and benign tissue. It might be worth further exploring area for this reason, especially given how strong of a right skew the malignant tissue has.

#### Smoothness
```{r}
# Basic distributions of these variables
ggplot(df) + 
  geom_histogram(aes(x = smoothness_mean, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  geom_vline(data= stats_mean, aes(xintercept = mean_smoothness, color = diagnosis), 
             linetype = "dashed") + 
  geom_vline(data= stats_mean, aes(xintercept = median_smoothness, color = diagnosis), 
             linetype = "solid") + 
  labs(x = "Smoothness (mean)", y = "Count",
       title = "Distribution of the Mean Smoothness by Diagnosis")
```

This distribution is fairly similar across both tissues although malignant does tend to have a higher mean and medina value of smoothness.

#### Compactness
```{r}
# Basic distributions of these variables
ggplot(df) + 
  geom_histogram(aes(x = compactness_mean, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  geom_vline(data= stats_mean, aes(xintercept = mean_compactness, color = diagnosis), 
             linetype = "dashed") + 
  geom_vline(data= stats_mean, aes(xintercept = median_compactness, color = diagnosis), 
             linetype = "solid") + 
  labs(x = "Compactness (mean)", y = "Count",
       title = "Distribution of the Mean Compactness by Diagnosis")
```

Similarly to area, the compactness is much more spread out for malignant tissue and has a stronger presence of outliers. However, the benign tissue is also right skewed a bit. Applying a transformation to both of these distributions might help to address the normality assumptions. 

#### Concavity
```{r}
# Basic distributions of these variables
ggplot(df) + 
  geom_histogram(aes(x = concavity_mean, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  geom_vline(data= stats_mean, aes(xintercept = mean_concavity, color = diagnosis), 
             linetype = "dashed") + 
  geom_vline(data= stats_mean, aes(xintercept = median_concavity, color = diagnosis), 
             linetype = "solid") + 
  labs(x = "Concavity (mean)", y = "Count",
       title = "Distribution of the Mean Concavity by Diagnosis")
```

Again, both malignant and benign are right skewed but benign has a stronger right skew in this distribution. Applying a transformation will be usefult o address the violation of normality assumptions.

#### Texture
```{r}
# Basic distributions of these variables
ggplot(df) + 
  geom_histogram(aes(x = concave.points_mean, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  geom_vline(data= stats_mean, aes(xintercept = mean_concave.points, color = diagnosis), 
             linetype = "dashed") + 
  geom_vline(data= stats_mean, aes(xintercept = median_concave.points, color = diagnosis), 
             linetype = "solid") + 
  labs(x = "Concave Points (mean)", y = "Count",
       title = "Distribution of the Mean Concave Points by Diagnosis")

```

The mean concave points are both fairly normally distributed with the malignant tissue having a much higher mean an median when comparing the types of tissue which could be something to explore further.

#### Symmetry
```{r}
# Basic distributions of these variables
ggplot(df) + 
  geom_histogram(aes(x = symmetry_mean, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  geom_vline(data= stats_mean, aes(xintercept = mean_symmetry, color = diagnosis), 
             linetype = "dashed") + 
  geom_vline(data= stats_mean, aes(xintercept = median_symmetry, color = diagnosis), 
             linetype = "solid") + 
  labs(x = "Symmetry (mean)", y = "Count",
       title = "Distribution of the Mean Symmetry by Diagnosis")

```
Symmetry has closer median values but malignant tissue has several outliers leading to a right skew in the distribution.

#### Fractal Dimension
```{r}
# Basic distributions of these variables
ggplot(df) + 
  geom_histogram(aes(x = fractal_dimension_mean, fill = diagnosis), alpha = 0.3) + 
  theme_bw() + 
  scale_fill_manual(values = pal, name = "Diagnosis") +
  scale_color_manual(values = pal, guide = "none") + 
  geom_vline(data= stats_mean, aes(xintercept = mean_fractal_dimension, 
                                    color = diagnosis), 
             linetype = "dashed") + 
  geom_vline(data= stats_mean, aes(xintercept = median_fractal_dimension, 
                                    color = diagnosis), 
             linetype = "solid") + 
  labs(x = "Fractal Dimension (mean)", y = "Count",
       title = "Distribution of the Mean Fractal Dimension by Diagnosis")
```
Both of these distributions are right skewed, but they are fairly close in terms of how they overal over each other. Transforming this feature might be a good idea to address the normality assumptions.

```{r}
corr_matrix <- df |> 
  select(ends_with("_mean")) |> 
  cor()

corrplot::corrplot(corr_matrix, method = "color", type = "upper", tl.cex = 0.7)
```

```{r}
corr_matrix <- df |> 
  select(ends_with("_worst")) |> 
  cor()

corrplot::corrplot(corr_matrix, method = "color", type = "upper", tl.cex = 0.7)

corr_matrix
```

```{r}

corr_matrix <- df |>
  select("concave.points_mean", "radius_se", "smoothness_se", "radius_worst", "texture_worst", "smoothness_worst", "concavity_worst", "concave.points_worst", "symmetry_worst") |> 
  cor()

corrplot::corrplot(corr_matrix, method = "color", type = "upper", tl.cex = 0.7)

corr_matrix
diag(corr_matrix) <- 0  # remove diagonal

weak_pairs <- corr_matrix |>
  as.data.frame() |>
  rownames_to_column("var1") |>
  pivot_longer(-var1, names_to = "var2", values_to = "cor") |>
  filter(var1 < var2,
         cor > -0.2,
         cor < 0.2)

weak_pairs
```



```{r}
pairs(df[, c("radius_mean", "texture_mean", "perimeter_mean", "area_mean", "smoothness_mean")])
```


SUPPORT VECTOR MACHINES


```{r}
#install.packages('e1071') 
#install.packages('caTools')
#install.packages('ggplot2')
#install.packages('caret')

library(caret)
library(e1071) 
library(caTools)
library(ggplot2)
```

```{r}
#update.packages("caTools", checkBuilt = TRUE)
```



```{r}
library(caTools)
set.seed(123)
split <- sample.split(df, SplitRatio = 0.8)
training <- subset(df, split == TRUE)
test <- subset(df, split == FALSE)

training$diagnosis <- as.factor(training$diagnosis)
test$diagnosis <- as.factor(test$diagnosis)


X_train = training[,-2]
y_train = training[,2]
X_test = test[,-2]
y_test = test[,2]
classifier <- svm(diagnosis ~ ., data = training, type = 'C-classification', kernel = 'radial', gamma = 0.1)
y_pred <- predict(classifier, newdata = test)

table(test$diagnosis, y_pred)

accuracy <- sum(diag(table(test$diagnosis, y_pred))) / sum(table(test$diagnosis, y_pred))
cat("Accuracy: ", accuracy)

confusionMatrix(table(test$diagnosis, y_pred))
```
```{r}
classifier
```

```{r}
library(caTools)
set.seed(123)
split <- sample.split(df, SplitRatio = 0.8)
training <- subset(df, split == TRUE)
test <- subset(df, split == FALSE)

training$diagnosis <- as.factor(training$diagnosis)
test$diagnosis <- as.factor(test$diagnosis)


X_train = training[,-2]
y_train = training[,2]
X_test = test[,-2]
y_test = test[,2]
classifier <- svm(diagnosis ~ .^2, data = training, type = 'C-classification', kernel = 'radial', gamma = 0.1)
y_pred <- predict(classifier, newdata = test)

table(test$diagnosis, y_pred)

accuracy <- sum(diag(table(test$diagnosis, y_pred))) / sum(table(test$diagnosis, y_pred))
cat("Accuracy: ", accuracy)

confusionMatrix(table(test$diagnosis, y_pred))
```


```{r}
log_model <- glm(diagnosis ~ ., 
                 data = training, 
                 family = binomial)

# Predictions (probabilities)
prob_pred <- predict(log_model, newdata = test, type = "response")

# Convert probabilities → class labels (assumes "M" = positive class)
y_pred <- ifelse(prob_pred > 0.5, "M", "B")
y_pred <- factor(y_pred, levels = levels(test$diagnosis))

# Confusion matrix
cm <- table(test$diagnosis, y_pred)
print(cm)

# Accuracy
accuracy <- sum(diag(cm)) / sum(cm)
cat("Accuracy:", accuracy, "\n")

# caret confusion matrix (better stats)
confusionMatrix(y_pred, test$diagnosis)
```

```{r}
log_model <- glm(diagnosis ~ .^2, 
                 data = training, 
                 family = binomial)

# Predictions (probabilities)
prob_pred <- predict(log_model, newdata = test, type = "response")

# Convert probabilities → class labels (assumes "M" = positive class)
y_pred <- ifelse(prob_pred > 0.5, "M", "B")
y_pred <- factor(y_pred, levels = levels(test$diagnosis))

# Confusion matrix
cm <- table(test$diagnosis, y_pred)
print(cm)

# Accuracy
accuracy <- sum(diag(cm)) / sum(cm)
cat("Accuracy:", accuracy, "\n")

# caret confusion matrix (better stats)
confusionMatrix(y_pred, test$diagnosis)
```

```{r}
library(randomForest)
library(caret)

# Fit random forest (NO family=binomial)
rf_model <- randomForest(diagnosis ~ ., data = training)

# Predict probabilities for class "M" (positive class)
prob_pred <- predict(rf_model, newdata = test, type = "prob")[, "M"]

# Convert probabilities to class labels
y_pred <- ifelse(prob_pred > 0.5, "M", "B")
y_pred <- factor(y_pred, levels = levels(test$diagnosis))

# Confusion matrix
cm <- table(Actual = test$diagnosis, Predicted = y_pred)
print(cm)

# Accuracy
accuracy <- sum(diag(cm)) / sum(cm)
cat("Accuracy:", accuracy, "\n")

# caret confusion matrix (more detailed metrics)
confusionMatrix(y_pred, test$diagnosis)
```


The Breast Cancer Wisconsin (Diagnostic) Data Set describes characteristics of the cell nuclei of breast masses. The dataset consists of the mean, standard error and "worst" or largest of these features for these 10 features computred from each image: radium, texture, permimeter, area, smoothness, compactness, concavity, concave points, symmetry, and fractal dimension. The radius is the mean of distances from center to points along the perimeter. Texture is the stadnard deviation of gray-scale values). Perimeter measures the distance along the outside of the mass. Area measures how big the mass is. Smoothness is the local variation in radius lengths. Compactness is caclulated by perimeter^2/area - 1, respresenting how dense or elongated the mass is. Concavity is the severity of concave portions of the contour. Concave points is the number of concave portions of the contour. Symmetry is measured ??. Fractal dimension represents the roughness or complexity of the shape and is calculated by the "coastline approximation" -1. We use the ID number as identificaiton and the diagnosis is either M (malignant) or B (benign) and is our response variable. There are 569 observations, with 357 benign and 212 malignant. (mention how the numbers are okay), and there was no missing data to deal with. 


```{r}
#install.packages("rpart")
#install.packages("rpart.plot")
library(rpart)
library(rpart.plot)

tree_model <- rpart(diagnosis ~ concave.points_mean + radius_se + smoothness_se+ radius_worst + texture_worst+ smoothness_worst+concavity_worst+concave.points_worst+symmetry_worst, data = training, method = "class")

prp(tree_model, extra = 2, fallen.leaves = TRUE, type = 4)


tree_pred <- predict(tree_model, newdata = test, type = "class")
confusionMatrix(tree_pred, test$diagnosis)

```
```{r}
tree_model <- rpart(diagnosis ~ (concave.points_mean + radius_se + smoothness_se+ radius_worst + texture_worst+ smoothness_worst+concavity_worst+concave.points_worst+symmetry_worst)^2, data = training, method = "class")

prp(tree_model, extra = 2, fallen.leaves = TRUE, type = 4)


tree_pred <- predict(tree_model, newdata = test, type = "class")
confusionMatrix(tree_pred, test$diagnosis)
```
```{r}

library(mgcv)      # for gam
library(dplyr)
library(caret)     # confusionMatrix
library(pROC) 
gam_formula <- as.formula(
  "diagnosis ~ 
     s(concave.points_mean) + s(radius_se) + s(smoothness_se) +
     s(radius_worst) + s(texture_worst) + s(smoothness_worst) +
     s(concavity_worst) + s(concave.points_worst) + s(symmetry_worst) +
     # interactions (tensor product smooths)
     ti(radius_worst, concavity_worst) + 
     ti(radius_worst, concave.points_worst) +
     ti(smoothness_worst, concavity_worst) +
     ti(texture_worst, concavity_worst)"
)

# Fit the GAM (binomial family for logistic)
set.seed(42)
gam_model <- gam(gam_formula, data = training, family = binomial(link = "logit"),
                 method = "REML", select = TRUE)

# Model summary (check significant smooths and interactions)
summary(gam_model)
#plot(gam_model, pages = 1, rug = TRUE)  # visual checks

# Predict probabilities on the test set
prob_test <- predict(gam_model, newdata = test, type = "response")

# Convert probabilities to class labels (threshold 0.5; change if you want sensitivity-weighted)
pred_class <- factor(ifelse(prob_test >= 0.5, "M", "B"), levels = levels(training$diagnosis))

# Confusion matrix
conf_mat <- confusionMatrix(pred_class, test$diagnosis, positive = "M")
print(conf_mat)

accuracy <- mean(pred_class == test$diagnosis)

```
```{r}
auc(test$diagnosis, prob_test)
```

```{r}
# R script: Fit EBM via reticulate, predict, confusion matrix
# Run in R (RStudio recommended)

# ----- packages -----
if (!requireNamespace("reticulate", quietly = TRUE)) install.packages("reticulate")
if (!requireNamespace("dplyr", quietly = TRUE)) install.packages("dplyr")
if (!requireNamespace("caret", quietly = TRUE)) install.packages("caret")
if (!requireNamespace("pROC", quietly = TRUE)) install.packages("pROC")

library(reticulate)
library(dplyr)
library(caret)
library(pROC)

# Optionally set a virtualenv or conda env (uncomment & edit if you want)
# reticulate::use_virtualenv("r-reticulate", required = FALSE)
# reticulate::use_condaenv("r-reticulate", required = FALSE)

# ----- ensure python package 'interpret' is available -----
if (!py_module_available("interpret")) {
  message("Python package 'interpret' not found. Installing via py_install('interpret') ...")
  # This will install interpret and dependencies via pip in the active Python env
  reticulate::py_install("interpret", pip = TRUE)
}

# import the package
interpret <- import("interpret")
explainers <- interpret$explainers
EBM <- explainers$ExplainableBoostingClassifier

# ----- Prepare data: predictors X_train/X_test, labels y_train/y_test -----
# Replace these with your actual training/test frames already in R: `training` and `test`
# I assume 'diagnosis' is a factor with levels c("B", "M") as before.

# choose predictors (you can replace/select others)
predictors <- c("concave.points_mean", "radius_se", "smoothness_se",
                "radius_worst", "texture_worst", "smoothness_worst",
                "concavity_worst", "concave.points_worst", "symmetry_worst")

# Ensure predictors exist
stopifnot(all(predictors %in% names(training)))
stopifnot(all(predictors %in% names(test)))

# X (data frames) and y (binary 0/1)
X_train <- training %>% select(all_of(predictors))
X_test  <- test %>% select(all_of(predictors))

# Convert diagnosis to 0/1 (0 = benign "B", 1 = malignant "M")
y_train <- ifelse(as.character(training$diagnosis) == "M", 1L, 0L)
y_test  <- ifelse(as.character(test$diagnosis) == "M", 1L, 0L)

# Convert to Python-friendly objects (pandas DataFrame and numpy array)
pd <- import("pandas")
np <- import("numpy")

X_train_py <- r_to_py(as.data.frame(X_train))
X_test_py  <- r_to_py(as.data.frame(X_test))
y_train_py <- r_to_py(y_train)  # simple numpy array
y_test_py  <- r_to_py(y_test)

# ----- Fit the EBM -----
set.seed(42)
ebm <- EBM()  # you can pass arguments like max_bins, interactions, inner_bags etc.

# Fit can take a bit - this trains an interpretable boosting classifier
message("Fitting EBM (this may take a minute)...")
ebm$fit(X_train_py, y_train_py)

# ----- Predict probabilities & classes on test set -----
# predict_proba returns array[:,0]=prob of class 0, array[:,1]=prob of class 1
probs_test <- ebm$predict_proba(X_test_py)
# convert to R numeric vector of P(M) = column 2
prob_M <- as.numeric(py_to_r(probs_test))      # flatten -> matrix, may need to reshape
# If py_to_r produced a matrix-like list, do:
if (is.matrix(prob_M) || (is.array(prob_M) && length(dim(prob_M)) == 2)) {
  prob_M <- as.numeric(prob_M[,2])  # second column
} else if (is.list(prob_M) && length(prob_M) > 0) {
  # try alternative conversion
  prob_M <- sapply(py_to_r(probs_test), function(x) x[[2]])
}

pred_class <- factor(ifelse(prob_M > 0.5, "M", "B"), levels = levels(training$diagnosis))

# ----- Confusion matrix & accuracy -----
cm <- confusionMatrix(pred_class, test$diagnosis, positive = "M")
print(cm)

accuracy <- mean(pred_class == test$diagnosis)
cat("Accuracy:", round(accuracy, 4), "\n")

# AUC
roc_obj <- roc(response = test$diagnosis, predictor = prob_M, levels = rev(levels(test$diagnosis)))
cat("AUC:", round(auc(roc_obj), 4), "\n")
```


```{r}
library(reticulate)

# import correct module
interpret <- import("interpret")
EBM <- interpret$glassbox$ExplainableBoostingClassifier

# Fit model
ebm <- EBM()
ebm$fit(X_train_py, y_train_py)

# Predict P(M)
probs_test <- ebm$predict_proba(X_test_py)

# extract column 2 = class 1 probability
probs_r <- py_to_r(probs_test)
prob_M <- probs_r[,2]

# convert to class
pred_class <- ifelse(prob_M > 0.5, "M", "B")
pred_class <- factor(pred_class, levels = levels(test$diagnosis))

# evaluate
library(caret)
confusionMatrix(pred_class, test$diagnosis, positive = "M")

```


GAM

```{r}
ggplot(data = df, aes(x = radius_worst, y = concavity_worst)) +
  geom_point()

ggplot(data = df, aes(x = radius_worst, y = concave.points_worst)) +
  geom_point()

ggplot(data = df, aes(x = smoothness_worst, y = concavity_worst)) +
  geom_point()

ggplot(data = df, aes(x = texture_worst, y = concavity_worst)) +
  geom_point()
```

```{r}
ggplot(df, aes(radius_worst, concavity_worst, color = diagnosis)) +
  geom_point() +
  geom_smooth(method = "gam")

ggplot(df, aes(radius_worst, concave.points_worst, color = diagnosis)) +
  geom_point() +
  geom_smooth(method = "gam")

ggplot(df, aes(smoothness_worst, concavity_worst, color = diagnosis)) +
  geom_point() +
  geom_smooth(method = "gam")

ggplot(df, aes(texture_worst, concavity_worst, color = diagnosis)) +
  geom_point() +
  geom_smooth(method = "gam")

```



```{r}
library(mgcv)      # for gam
library(dplyr)
library(caret)     # confusionMatrix
library(pROC) 

# gam_formula <- as.formula(
#   "diagnosis ~ 
#      s(concave.points_mean) + s(radius_se) + s(smoothness_se) +
#      s(radius_worst) + s(texture_worst) + s(smoothness_worst) +
#      s(concavity_worst) + s(concave.points_worst) + s(symmetry_worst)"
# )
# 0.9597       

gam_formula <- as.formula(
  "diagnosis ~
     s(concave.points_mean) + s(radius_se) + s(smoothness_se) +
     s(radius_worst) + s(texture_worst) + s(smoothness_worst) +
     s(concavity_worst) + s(concave.points_worst) + s(symmetry_worst) +
     # interactions (tensor product smooths)
     ti(radius_worst, concavity_worst) +
     ti(radius_worst, concave.points_worst) +
     ti(smoothness_worst, concavity_worst) +
     ti(texture_worst, concavity_worst)"
)
# 0.9677

# #based on significant interactions for the for previous one
# gam_formula <- as.formula(
#   "diagnosis ~
#      s(concave.points_mean) + s(radius_se) + s(smoothness_se) +
#      s(radius_worst) + s(texture_worst) + s(smoothness_worst) +
#      s(concavity_worst) + s(concave.points_worst) + s(symmetry_worst) +
#      # interactions (tensor product smooths)
#      ti(radius_worst, concave.points_worst) +
#      ti(texture_worst, concavity_worst)"
# )
# #0.9597      

#based on significance for the for previous one
# gam_formula <- as.formula(
#   "diagnosis ~
#      s(concave.points_mean) + s(radius_se) + s(smoothness_se) +
#      s(radius_worst) + s(texture_worst) +  s(concave.points_worst) +
#      # interactions (tensor product smooths)
#      ti(radius_worst, concave.points_worst)"
# )
# #0.9597 

# predictors <- training |>
#   select(where(is.numeric)) |>
#   names()
# 
# # build GAM formula automatically: s(var1) + s(var2) + ...
# smooth_terms <- paste0("s(", predictors, ")", collapse = " + ")
# gam_formula <- as.formula(paste("diagnosis ~", smooth_terms))

# Fit the GAM (binomial family for logistic)
set.seed(42)
gam_model <- gam(gam_formula, data = training, family = binomial(link = "logit"),
                 method = "REML", select = TRUE)

# Model summary (check significant smooths and interactions)
summary(gam_model)
#plot(gam_model, pages = 1, rug = TRUE)  # visual checks

# Predict probabilities on the test set
prob_test <- predict(gam_model, newdata = test, type = "response")

# Convert probabilities to class labels (threshold 0.5; change if you want sensitivity-weighted)
pred_class <- factor(ifelse(prob_test >= 0.5, "M", "B"), levels = levels(training$diagnosis))

# Confusion matrix
conf_mat <- confusionMatrix(pred_class, test$diagnosis, positive = "M")
print(conf_mat)

accuracy <- mean(pred_class == test$diagnosis)
```


```{r}
# Robust IPC fit helper ----------------------------------------------------
fit_ipc_safe <- function(df, prob_col = "prob", intervent_col = "intervene", verbose = TRUE) {
  # required packages
  if (!requireNamespace("stats", quietly = TRUE)) stop("stats package required")
  
  # Basic checks
  if (!(prob_col %in% names(df))) stop("prob column not found: ", prob_col)
  if (!(intervent_col %in% names(df))) stop("intervene column not found: ", intervent_col)
  
  x_raw <- df[[prob_col]]
  y_raw <- df[[intervent_col]]
  
  # Report problematic rows
  bad_idx <- which(!is.finite(x_raw) | is.na(x_raw) | !is.finite(y_raw) | is.na(y_raw))
  if (length(bad_idx) > 0) {
    if (verbose) {
      message("Found non-finite / NA rows. Showing up to 10 of them:")
      print(utils::head(df[bad_idx, , drop = FALSE], 10))
    }
    # Option: drop them
    df <- df[-bad_idx, , drop = FALSE]
    x_raw <- df[[prob_col]]; y_raw <- df[[intervent_col]]
  }
  
  # Coerce intervene to numeric 0/1 if needed
  if (!is.numeric(y_raw)) {
    if (verbose) message("Converting intervene to numeric 0/1 based on unique values.")
    # attempt smart conversion
    if (all(levels(as.factor(y_raw)) %in% c("0","1"))) {
      y_raw <- as.numeric(as.character(y_raw))
    } else {
      # map anything truthy to 1, others 0 (common cases: TRUE/FALSE, "yes"/"no", "Y"/"N")
      y_raw <- as.character(y_raw)
      y_raw_lower <- tolower(y_raw)
      y_raw_num <- ifelse(y_raw_lower %in% c("1","t","true","yes","y"), 1L,
                          ifelse(y_raw_lower %in% c("0","f","false","no","n"), 0L, NA))
      if (any(is.na(y_raw_num))) {
        stop("Cannot safely convert intervene column to 0/1. Inspect values: ",
             paste(unique(y_raw)[1:min(10, length(unique(y_raw)))], collapse = ", "))
      }
      y_raw <- y_raw_num
    }
  }
  
  # clamp probabilities into (eps, 1-eps)
  eps <- 1e-8
  if (any(x_raw <= 0 | x_raw >= 1)) {
    if (verbose) message("Clamping probabilities into (", eps, ", ", 1 - eps, ").")
    x_raw <- pmin(pmax(x_raw, eps), 1 - eps)
  }
  
  # rebuild cleaned df
  df_clean <- data.frame(prob = as.numeric(x_raw), intervene = as.numeric(y_raw))
  if (nrow(df_clean) < 10) stop("Too few rows after cleaning: ", nrow(df_clean))
  
  # IPC helper functions (safe transforms)
  ipc_fun <- function(params, x) {
    # params: c(mu, log_sigma, logit_C0, logit_C1)
    mu <- params[1]
    sigma <- exp(params[2])        # enforce >0
    C0 <- 1 / (1 + exp(-params[3]))  # plogis
    C1 <- 1 / (1 + exp(-params[4]))
    # make sure sum <= 0.999
    ssum <- C0 + C1
    if (ssum >= 0.999) {
      C0 <- C0 * 0.999 / ssum
      C1 <- C1 * 0.999 / ssum
    }
    # safe pnorm call
    p <- stats::pnorm((x - mu) / sigma)
    (1 - C0 - C1) * p + C0
  }
  
  ipc_rss <- function(par, x, y) {
    # return large finite value if any NA/NaN occurs
    preds <- tryCatch(ipc_fun(par, x), error = function(e) rep(NA_real_, length(x)))
    if (any(!is.finite(preds))) return(1e30)
    sum((y - preds)^2)
  }
  
  # sensible initial params:
  mu0 <- mean(df_clean$prob)        # center
  sigma0 <- max(0.05, sd(df_clean$prob) / 3)  # positive
  # C0 = observed min proportion; C1 = 1 - observed max proportion (rough)
  # Estimate empirical low/high offsets by small bins:
  b <- cut(df_clean$prob, breaks = seq(0,1,by = 0.05), include.lowest = TRUE)
  agg <- aggregate(df_clean$intervene, by = list(b), FUN = mean)
  C0_init <- min(agg$x, na.rm = TRUE)
  C1_init <- 1 - max(agg$x, na.rm = TRUE)
  C0_init <- pmin(pmax(C0_init, 0.001), 0.2)  # reasonable range
  C1_init <- pmin(pmax(C1_init, 0.001), 0.99)
  
  init <- c(mu0, log(sigma0), qlogis(C0_init), qlogis(C1_init))
  names(init) <- c("mu", "log_sigma", "logit_C0", "logit_C1")
  if (verbose) {
    message("Initial params (mu, sigma, C0, C1): ",
            paste(round(c(mu0, sigma0, C0_init, C1_init), 4), collapse = ", "))
  }
  
  # run optim with protections
  opt_try <- tryCatch({
    stats::optim(par = init, fn = ipc_rss, x = df_clean$prob, y = df_clean$intervene,
                 method = "L-BFGS-B",
                 lower = c(-5, log(1e-6), qlogis(1e-6), qlogis(1e-6)),
                 upper = c(5, log(5), qlogis(0.999), qlogis(0.999)),
                 control = list(maxit = 2000))
  }, error = function(e) e)
  
  if (inherits(opt_try, "error") || opt_try$convergence != 0) {
    if (verbose) message("optim failed or did not converge; trying nlminb fallback...")
    # fallback to nlminb (often more stable)
    nl_try <- tryCatch({
      stats::nlminb(start = init, objective = ipc_rss, x = df_clean$prob, y = df_clean$intervene,
                    control = list(iter.max = 2000, eval.max = 2000))
    }, error = function(e) e)
    
    if (inherits(nl_try, "error") || nl_try$convergence != 0) {
      stop("Both optim and nlminb failed. Last nlminb output:\n",
           capture.output(str(nl_try)))
    } else {
      opt_res <- nl_try
      par_hat <- nl_try$par
      value <- nl_try$objective
    }
  } else {
    opt_res <- opt_try
    par_hat <- opt_try$par
    value <- opt_try$value
  }
  
  # convert back to natural params
  mu_hat <- par_hat[1]
  sigma_hat <- exp(par_hat[2])
  C0_hat <- 1 / (1 + exp(-par_hat[3]))
  C1_hat <- 1 / (1 + exp(-par_hat[4]))
  # enforce sum <= 0.999
  if ((C0_hat + C1_hat) >= 0.999) {
    scale <- 0.999 / (C0_hat + C1_hat)
    C0_hat <- C0_hat * scale; C1_hat <- C1_hat * scale
  }
  TO <- mu_hat - sigma_hat
  TI <- mu_hat + sigma_hat
  
  res <- list(
    params_raw = par_hat,
    mu = mu_hat,
    sigma = sigma_hat,
    C0 = C0_hat,
    C1 = C1_hat,
    TO = TO,
    TI = TI,
    rss = value,
    optim_res = opt_res,
    df_clean = df_clean
  )
  class(res) <- "ipc_fit"
  if (verbose) {
    message("Fit complete. TO=", round(TO,4), " TI=", round(TI,4),
            " C0=", round(C0_hat,4), " C1=", round(C1_hat,4))
  }
  res
}

# Example usage:
# df <- data.frame(prob = prob_test, intervene = as.integer(test$invasive_flag))
# ipc_res <- fit_ipc_safe(df)
# ipc_res

# Plot helper (if fit successful)
plot.ipc_fit <- function(ipc_res) {
  dfc <- ipc_res$df_clean
  newx <- seq(0,1,length.out = 400)
  parvec <- ipc_res$params_raw
  ipc_fun_local <- function(par, x) {
    mu <- par[1]; sigma <- exp(par[2]); C0 <- 1/(1+exp(-par[3])); C1 <- 1/(1+exp(-par[4]))
    if ((C0+C1)>=0.999){ scale<-0.999/(C0+C1); C0<-C0*scale; C1<-C1*scale }
    (1 - C0 - C1) * pnorm((x - mu)/sigma) + C0
  }
  pred_line <- ipc_fun_local(parvec, newx)
  df_bins <- dfc %>%
    dplyr::mutate(bin = cut(prob, breaks = seq(0,1,by=0.02), include.lowest = TRUE)) %>%
    dplyr::group_by(bin) %>%
    dplyr::summarize(prob_mean = mean(prob), prop = mean(intervene), n = n()) %>%
    dplyr::filter(!is.na(prob_mean))
  library(ggplot2)
  ggplot() +
    geom_point(data = df_bins, aes(x = prob_mean, y = prop, size = n), alpha = 0.6) +
    geom_line(data = data.frame(prob = newx, ipc = pred_line), aes(prob, ipc), color = "blue", size = 1) +
    geom_vline(xintercept = c(ipc_res$TO, ipc_res$TI), linetype = "dashed", color = "red") +
    labs(x = "predicted probability", y = "observed intervention rate",
         title = "IPC fit") +
    theme_minimal()
}

```

```{r}
df <- data.frame(prob = prob_test, intervene = as.integer(test$invasive_flag))
ipc_res <- fit_ipc_safe(df)
plot(ipc_res)

```



```{r}
# Requires: stats (base)
library(stats)

# Example inputs: vecs of length N
# probs = predicted probabilities (0..1)
# inter = intervention indicator (0/1)

fit_ipc_once <- function(probs, inter, breaks = seq(0,1,by=0.05)) {
  # bin into equal-width bins
  bin <- cut(probs, breaks = breaks, include.lowest = TRUE, right = FALSE)
  df <- aggregate(inter, by = list(bin=bin), FUN = function(x) c(n=length(x), sum=sum(x)))
  # unpack
  n <- sapply(df$x, "[", 1)
  sums <- sapply(df$x, "[", 2)
  # compute mean prob per bin (use midpoints or mean actual probs)
  mids <- tapply(probs, bin, mean)
  prop <- sums / n
  df2 <- data.frame(x = as.numeric(mids), prop = prop, n = n)
  df2 <- na.omit(df2)

  # IPC function: (1 - C0 - C1) * pnorm((x - mu)/sigma) + C0
  # initial params (simple guesses)
  start <- list(mu = 0.2, sigma = 0.1, C0 = 0, C1 = 0.3)
  nlsfit <- nls(prop ~ (1 - C0 - C1) * pnorm((x - mu)/sigma) + C0,
                data = df2,
                start = start,
                algorithm = "port",
                lower = c(mu = -1, sigma = 1e-6, C0 = 0, C1 = 0),
                upper = c(mu = 2,    sigma = 1,      C0 = 1, C1 = 1),
                trace = FALSE,
                control = nls.control(maxiter = 200))
  co <- coef(nlsfit)
  mu <- co["mu"]; sigma <- co["sigma"]; C0 <- co["C0"]; C1 <- co["C1"]
  T_O <- mu - sigma
  T_I <- mu + sigma
  return(list(mu=mu, sigma=sigma, C0=C0, C1=C1, T_O=T_O, T_I=T_I, fit = nlsfit, binned = df2))
}

# Bootstrap + dither approach
fit_ipc_bootstrap <- function(probs, inter, B = 100, breaks = seq(0,1,by=0.05), dither_sd = 0.01) {
  res <- replicate(B, {
    idx <- sample(seq_along(probs), replace = TRUE)
    p2 <- probs[idx] + rnorm(length(idx), sd = dither_sd) # dither
    p2 <- pmin(1, pmax(0, p2))
    it2 <- inter[idx]
    s <- tryCatch(fit_ipc_once(p2, it2, breaks = breaks), error = function(e) NULL)
    if (is.null(s)) return(NA)
    c(mu = s$mu, sigma = s$sigma, C0 = s$C0, C1 = s$C1, T_O = s$T_O, T_I = s$T_I)
  }, simplify = "array")
  res <- t(res)
  colnames(res) <- c("mu","sigma","C0","C1","T_O","T_I")
  # remove rows with NA (failed fits)
  res <- res[complete.cases(res), , drop = FALSE]
  # point estimates = medians; CI = 2.5/97.5 percentiles
  est <- apply(res, 2, median)
  ci_low <- apply(res, 2, quantile, 0.025)
  ci_high <- apply(res, 2, quantile, 0.975)
  return(list(samples = res, est = est, ci_low = ci_low, ci_high = ci_high))
}

# USAGE example (replace probs/inter with your data)
out <- fit_ipc_bootstrap(prob_test, df$diagnosis, B = 100, breaks = seq(0,1,by=0.05))
out$est["T_O"]; out$est["T_I"]
out$ci_low["T_O"]; out$ci_high["T_I"]

```
```{r}
df$diagnosis[1:20]
```
```{r}
# Robust IPC fit + bootstrap (handles empty bins and alignment correctly)
ipc_fit_once <- function(probs, inter, breaks = seq(0,1,by=0.05)) {
  if (length(probs) != length(inter)) stop("probs and inter must be same length")
  # assign bins
  bins <- cut(probs, breaks = breaks, include.lowest = TRUE, right = FALSE)
  # number in each bin
  ns <- as.integer(tapply(probs, bins, length))
  # sum of interventions in each bin (NA for empty)
  sums <- as.numeric(tapply(inter, bins, sum))
  # mean prob per bin (NA for empty)
  means <- as.numeric(tapply(probs, bins, mean))
  # keep only bins with at least one observation
  ok <- which(ns > 0 & !is.na(means) & !is.na(sums))
  if (length(ok) < 4) {
    # not enough bins to fit reliably
    return(rep(NA_real_, 6))
  }
  x_vals <- means[ok]
  prop_vals <- sums[ok] / ns[ok]

  bdf <- data.frame(x = x_vals, prop = prop_vals)

  # initial guesses
  start_vals <- list(mu = median(bdf$x), sigma = 0.1, C0 = 0, C1 = 0.1)
  fit <- tryCatch({
    nls(prop ~ (1 - C0 - C1) * pnorm((x - mu)/sigma) + C0,
        data = bdf,
        start = start_vals,
        algorithm = "port",
        lower = c(mu=-1, sigma=1e-6, C0=0, C1=0),
        upper = c(mu=2,  sigma=1,    C0=1, C1=1),
        control = nls.control(maxiter = 200))
  }, error = function(e) NULL)

  if (is.null(fit)) return(rep(NA_real_, 6))

  co <- coef(fit)
  mu <- co["mu"]; sigma <- co["sigma"]; C0 <- co["C0"]; C1 <- co["C1"]
  T_O <- mu - sigma; T_I <- mu + sigma
  c(mu = mu, sigma = sigma, C0 = C0, C1 = C1, T_O = T_O, T_I = T_I)
}

fit_ipc_bootstrap <- function(probs, inter, B = 100,
                              breaks = seq(0,1,by=0.05), dither_sd = 0.01) {
  if (length(probs) != length(inter)) stop("probs and inter must be same length")
  N <- length(probs)
  results <- matrix(NA_real_, nrow = B, ncol = 6)
  colnames(results) <- c("mu","sigma","C0","C1","T_O","T_I")

  for (b in seq_len(B)) {
    idx <- sample.int(N, N, replace = TRUE)
    p2 <- probs[idx] + rnorm(N, mean = 0, sd = dither_sd)
    p2 <- pmin(1, pmax(0, p2))  # keep in [0,1]
    i2 <- inter[idx]
    results[b, ] <- ipc_fit_once(p2, i2, breaks = breaks)
  }

  good <- apply(!is.na(results), 1, any)
  if (!any(good)) stop("All IPC fits failed. Try different breaks or check data.")
  samples_good <- results[good, , drop = FALSE]

  est <- apply(samples_good, 2, median, na.rm = TRUE)
  ci_low  <- apply(samples_good, 2, quantile, 0.025, na.rm = TRUE)
  ci_high <- apply(samples_good, 2, quantile, 0.975, na.rm = TRUE)

  list(samples = samples_good, est = est, ci_low = ci_low, ci_high = ci_high)
}



out <- fit_ipc_bootstrap(prob_train, y_train, B = 100, breaks = seq(0,1,by=0.05))

out$est
out$ci_low
out$ci_high

```

```{r}
prob_train <- predict(cvfit, newx = X_train, 
                     s = "lambda.min", 
                     type = "response")
prob_train <- as.numeric(prob_train)
length(prob_test)
length(df$diagnosis)
```

```{r}
#train_idx <- sample(seq_len(n), size = 0.8 * n)

diagnosis_train <- df[train_idx, ][, -1]
diagnosis_train
```

